{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Autoencoder\n",
    "> [Alik604](https://github.com/alik604/youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# !pip install mlxtend catboost scikit-plot xgboost lightgbm\n",
    "\n",
    "import xgboost  # xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "import lightgbm # lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "import catboost # catboost.ai/docs/concepts/python-quickstart.html\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import * \n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 274)\n",
      "(452, 1)\n",
      "(452,)\n"
     ]
    }
   ],
   "source": [
    "mat = loadmat('arrhythmia.mat')\n",
    "# SRC: http://odds.cs.stonybrook.edu/arrhythmia-dataset/\n",
    "# Description: X = Multi-dimensional point data, y = labels (1 = outliers, 0 = inliers)\n",
    "\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y = y.ravel()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portion_of_outliers 0.14601769911504425\n"
     ]
    }
   ],
   "source": [
    "portion_of_outliers = np.sum(y)/len(y) # (1 = outliers, 0 = inliers)\n",
    "print(\"portion_of_outliers\", portion_of_outliers)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 273 with a variance ratio of 1.0\n",
      "i = 253 with a variance ratio of 1.0\n",
      "i = 233 with a variance ratio of 1.0\n",
      "i = 213 with a variance ratio of 1.0\n",
      "i = 193 with a variance ratio of 1.0\n",
      "i = 173 with a variance ratio of 1.0\n",
      "i = 153 with a variance ratio of 0.99999\n",
      "i = 133 with a variance ratio of 0.99996\n",
      "i = 113 with a variance ratio of 0.99981\n",
      "i = 93 with a variance ratio of 0.99906\n",
      "i = 73 with a variance ratio of 0.99562\n",
      "i = 53 with a variance ratio of 0.9829\n",
      "i = 33 with a variance ratio of 0.93978\n",
      "i = 13 with a variance ratio of 0.77919\n",
      "We should set n_components to:  73\n"
     ]
    }
   ],
   "source": [
    "wanted_explained_variance_ratio = 0.99\n",
    "steps_down = 20\n",
    "wanted_n_components = X_train.shape[1]\n",
    "first_time = True\n",
    "\n",
    "for i in range(X_train.shape[1]-1, 1, -steps_down):\n",
    "  total_var_ratio = round(np.sum(PCA(n_components=i).fit(X_train).explained_variance_ratio_), 5)\n",
    "  print('i =', i, 'with a variance ratio of', total_var_ratio)\n",
    "  if total_var_ratio < wanted_explained_variance_ratio and first_time:\n",
    "    wanted_n_components = i + steps_down\n",
    "    first_time = False\n",
    "#     break\n",
    "\n",
    "print(\"We should set n_components to: \", wanted_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(X_train, X_test, y_train = y_train, y_test = y_test, verbose = False, scale = False, run_PCA = None, title = ''):    \n",
    "    print(\"\\n=======================================\")\n",
    "    print(title)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if run_PCA:\n",
    "        pca = PCA(n_components=run_PCA)\n",
    "        _ = pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "    DTC = DecisionTreeClassifier() \n",
    "    RFC = RandomForestClassifier(n_estimators=250, n_jobs=-1)\n",
    "    ETC = ExtraTreesClassifier(n_estimators=250, n_jobs=-1)\n",
    "    XGB = xgboost.XGBClassifier(n_estimators=250, n_jobs=-1)\n",
    "    GBM = lightgbm.LGBMClassifier(n_estimators=200, n_jobs=-1)\n",
    "#     RFC = RandomForestClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     ETC = ExtraTreesClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     XGB = xgboost.XGBClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     GBM = lightgbm.LGBMClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "    list_of_CLFs_names = []\n",
    "    list_of_CLFs = [DTC, RFC, ETC, XGB, GBM]\n",
    "    ranking = []\n",
    "\n",
    "    for clf in list_of_CLFs: \n",
    "        _ = clf.fit(X_train,y_train)\n",
    "        pred = clf.score(X_test,y_test)\n",
    "        name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "        if verbose:\n",
    "            print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "        \n",
    "        ranking.append(pred)\n",
    "        list_of_CLFs_names.append(name)\n",
    "\n",
    "    # drop any subpar classifier \n",
    "    best = np.max(ranking)\n",
    "    avg = np.sum(ranking)/len(ranking)\n",
    "    variance = best - avg \n",
    "    to_remove = ranking - avg + variance\n",
    "    to_remove_alt = ranking - best + variance\n",
    "    # print(list_of_CLFs_names)\n",
    "    # print(to_remove)      \n",
    "    # print(to_remove_alt)\n",
    "\n",
    "    ranking = np.array(ranking)[to_remove > 0]\n",
    "    list_of_CLFs = np.array(list_of_CLFs)[to_remove > 0]\n",
    "\n",
    "    eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, refit=False, voting='soft')\n",
    "    eclf.fit(X_train, y_train)\n",
    "    pred = eclf.predict(X_test)\n",
    "    probas = eclf.predict_proba(X_test)\n",
    "    acc = eclf.score(X_test, y_test)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Acc: %0.5f for the %s\" % (acc, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "#     print(\"F1 score: \\t\\t\", round(f1_score(y_test, pred, average='micro'), 3))                # 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"Log loss (categorical cross entropy): \\t\", round(log_loss(y_test, probas), 3)) # -log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "\n",
    "    if verbose:\n",
    "        skplt.metrics.plot_roc(y_true=y_test, y_probas=probas)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "No Scaling, no PCA, Dim:274\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.94505 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.171\n",
      "\n",
      "=======================================\n",
      "Scaling, no PCA\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.95604 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.18\n",
      "\n",
      "=======================================\n",
      "No scaling, PCA:73\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.90110 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.27\n",
      "\n",
      "=======================================\n",
      "Scaling, PCA:73\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.90110 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.276\n"
     ]
    }
   ],
   "source": [
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = False, title= \"No Scaling, no PCA, Dim:\" + str(X_train.shape[1]) )\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = True , run_PCA = False, title= \"Scaling, no PCA\")\n",
    "\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = wanted_n_components, title= \"No scaling, PCA:\" +str(wanted_n_components))\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = True, run_PCA = wanted_n_components, title= \"Scaling, PCA:\" +str(wanted_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "No scaling, PCA:30\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.91209 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.269\n",
      "\n",
      "=======================================\n",
      "No scaling, PCA:2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.85714 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.475\n",
      "\n",
      "=======================================\n",
      "Scaling, PCA:2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.85714 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.478\n"
     ]
    }
   ],
   "source": [
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 30, title= \"No scaling, PCA:\" +str(30))\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 2, title= \"No scaling, PCA:\" +str(2))\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = True, run_PCA = 2, title= \"Scaling, PCA:\" +str(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a autoenoder to 'beat' the proformance of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324 samples, validate on 37 samples\n",
      "Epoch 1/250\n",
      "324/324 [==============================] - 0s 2ms/sample - loss: 0.8905 - val_loss: 0.8981\n",
      "Epoch 2/250\n",
      "324/324 [==============================] - 0s 557us/sample - loss: 0.8553 - val_loss: 0.8891\n",
      "Epoch 3/250\n",
      "324/324 [==============================] - 0s 559us/sample - loss: 0.8151 - val_loss: 0.8827\n",
      "Epoch 4/250\n",
      "324/324 [==============================] - 0s 574us/sample - loss: 0.7982 - val_loss: 0.8886\n",
      "Epoch 5/250\n",
      "324/324 [==============================] - 0s 515us/sample - loss: 0.7958 - val_loss: 0.8880\n",
      "Epoch 6/250\n",
      "324/324 [==============================] - 0s 485us/sample - loss: 0.7798 - val_loss: 0.8810\n",
      "Epoch 7/250\n",
      "324/324 [==============================] - 0s 515us/sample - loss: 0.7737 - val_loss: 0.8870\n",
      "Epoch 8/250\n",
      "324/324 [==============================] - 0s 556us/sample - loss: 0.7726 - val_loss: 0.8999\n",
      "Epoch 9/250\n",
      "324/324 [==============================] - 0s 549us/sample - loss: 0.7650 - val_loss: 0.8800\n",
      "Epoch 10/250\n",
      "324/324 [==============================] - 0s 509us/sample - loss: 0.7477 - val_loss: 0.8823\n",
      "Epoch 11/250\n",
      "324/324 [==============================] - 0s 469us/sample - loss: 0.7437 - val_loss: 0.8854\n",
      "Epoch 12/250\n",
      "324/324 [==============================] - 0s 466us/sample - loss: 0.7390 - val_loss: 0.8832\n",
      "Epoch 13/250\n",
      "324/324 [==============================] - 0s 463us/sample - loss: 0.7365 - val_loss: 0.8887\n",
      "Epoch 14/250\n",
      "324/324 [==============================] - 0s 469us/sample - loss: 0.7376 - val_loss: 0.8880\n",
      "Epoch 15/250\n",
      "324/324 [==============================] - 0s 469us/sample - loss: 0.7301 - val_loss: 0.8871\n",
      "Epoch 16/250\n",
      "324/324 [==============================] - 0s 627us/sample - loss: 0.7218 - val_loss: 0.8892\n",
      "MSE: 268.45\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512,  activation='elu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128,  activation='elu'))\n",
    "\n",
    "model.add(Dense(2,    activation='linear', name=\"bottleneck\")) # elu activation yeilds [-1, -1, NUMB]\n",
    "\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(128,  activation='elu'))\n",
    "model.add(Dense(512,  activation='elu'))\n",
    "model.add(Dense(X_train.shape[1],  activation='elu'))\n",
    "model.compile(loss='mean_squared_error', optimizer = Adam(0.0005))\n",
    "\n",
    "\n",
    "ES = EarlyStopping(patience=7, restore_best_weights=True)\n",
    "history = model.fit(X_train, X_train, batch_size=4, epochs=250, verbose=1, validation_split = 0.1, callbacks =[ES])\n",
    "print(f'MSE: {np.sum(((X_train-model.predict(X_train))**2).mean(axis=1)):.2f}')\n",
    "\n",
    "encoder = Model(model.input, model.get_layer('bottleneck').output)\n",
    "embedding = encoder.predict(X_train)  # bottleneck representation\n",
    "\n",
    "\n",
    "#Acc: 0.85714 for the EnsembleVoteClassifier | PCA(2) | Log loss: 0.487\n",
    "#Acc: 0.89011 for the EnsembleVoteClassifier | AE(2) | Log loss: 0.498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 2)\n",
      "[-1.7372092  1.3490907]\n"
     ]
    }
   ],
   "source": [
    "X_train_dimRect_via_AE = encoder.predict(X_train)\n",
    "X_test_dimRect_via_AE = encoder.predict(X_test)\n",
    "print(X_train_dimRect_via_AE.shape)\n",
    "\n",
    "print(X_train_dimRect_via_AE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "PCA: 2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.85714 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.5\n",
      "\n",
      "=======================================\n",
      "Autoencoder's embedding dim: 2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.87912 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.381\n"
     ]
    }
   ],
   "source": [
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 2, title= \"PCA: \" + str(2)) # PCA(2): 89%\n",
    "benchmark(X_train_dimRect_via_AE, X_test_dimRect_via_AE, y_train, y_test, scale = False, run_PCA = False, title= \"Autoencoder's embedding dim: \" + str(X_train_dimRect_via_AE.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 92% with PCA - 0.99\n",
    "# 94% without PCA NOR Standard Scaler \n",
    "# 94% with only Standard Scaler \n",
    "\n",
    "## best out of 5 tested\n",
    "# Acc: 0.82418 for the LGBMClassifier on 2D VIA AE - few epochs \n",
    "# Acc: 0.79121 for the LGBMClassifier on 2D VIA AE - many epochs\n",
    "# Acc: 0.81319 for the LGBMClassifier on 2D VIA AE - many epochs & Dropout(0.4)\n",
    "# Acc: 0.85714 for the LGBMClassifier on 2D VIA AE - many epochs & Dropout(0.4) & Smaller batch_size (128 -> 16)\n",
    "# Acc: 0.86813 for the LGBMClassifier on 2D VIA AE - many epochs & Smaller batch_size (128 -> 16);  Acc: 0.90110 for the DecisionTreeClassifier\n",
    "# Acc: 0.89011 for the ExtraTreesClassifier        - via chance??  \n",
    "# Acc: 0.93407 for the XGBClassifier               - many epochs & Dropout(0.4) & Smaller batch_size \n",
    "\n",
    "# Acc: 0.83516 for the LGBMClassifier on 2D via PCA\n",
    "\n",
    "\n",
    "# output of PCA(2)\n",
    "# Acc: 0.75824 for the DecisionTreeClassifier\n",
    "# Acc: 0.86813 for the RandomForestClassifier\n",
    "# Acc: 0.83516 for the ExtraTreesClassifier\n",
    "# Acc: 0.86813 for the XGBClassifier\n",
    "# Acc: 0.83516 for the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.450175439129"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # much faster \n",
    "# mses = ((X_train-model.predict(X_train))**2).mean(axis=1)\n",
    "# np.sum(mses)\n",
    "\n",
    "# count = 0\n",
    "# pred = model.predict(X_train)\n",
    "# for i in range(361):\n",
    "#     for j in range(X_train.shape[1]):\n",
    "#         count += (X_train[i][j] - pred[i][j])**2\n",
    "# count /= X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
