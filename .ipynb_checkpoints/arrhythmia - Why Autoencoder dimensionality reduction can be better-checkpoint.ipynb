{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomally Detection on the Arrhythmia dataset\n",
    "> Alik604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install mlxtend catboost scikit-plot xgboost lightgbm\n",
    "\n",
    "import xgboost  # xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "import lightgbm # lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "import catboost # catboost.ai/docs/concepts/python-quickstart.html\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import * \n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 274)\n",
      "(452, 1)\n",
      "(452,)\n"
     ]
    }
   ],
   "source": [
    "mat = loadmat('arrhythmia.mat')\n",
    "# SRC: http://odds.cs.stonybrook.edu/arrhythmia-dataset/\n",
    "# Description: X = Multi-dimensional point data, y = labels (1 = outliers, 0 = inliers)\n",
    "\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y = y.ravel()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portion_of_outliers 0.14601769911504425\n"
     ]
    }
   ],
   "source": [
    "portion_of_outliers = np.sum(y)/len(y) # (1 = outliers, 0 = inliers)\n",
    "print(\"portion_of_outliers\", portion_of_outliers)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 273 with a variance ratio of 1.0\n",
      "i = 253 with a variance ratio of 1.0\n",
      "i = 233 with a variance ratio of 1.0\n",
      "i = 213 with a variance ratio of 1.0\n",
      "i = 193 with a variance ratio of 1.0\n",
      "i = 173 with a variance ratio of 1.0\n",
      "i = 153 with a variance ratio of 0.99999\n",
      "i = 133 with a variance ratio of 0.99996\n",
      "i = 113 with a variance ratio of 0.99981\n",
      "i = 93 with a variance ratio of 0.99906\n",
      "i = 73 with a variance ratio of 0.99562\n",
      "i = 53 with a variance ratio of 0.9829\n",
      "i = 33 with a variance ratio of 0.93978\n",
      "i = 13 with a variance ratio of 0.77919\n",
      "We should set n_components to:  73\n"
     ]
    }
   ],
   "source": [
    "wanted_explained_variance_ratio = 0.99\n",
    "steps_down = 20\n",
    "wanted_n_components = X_train.shape[1]\n",
    "first_time = True\n",
    "\n",
    "for i in range(X_train.shape[1]-1, 1, -steps_down):\n",
    "  total_var_ratio = round(np.sum(PCA(n_components=i).fit(X_train).explained_variance_ratio_), 5)\n",
    "  print('i =', i, 'with a variance ratio of', total_var_ratio)\n",
    "  if total_var_ratio < wanted_explained_variance_ratio and first_time:\n",
    "    wanted_n_components = i + steps_down\n",
    "    first_time = False\n",
    "#     break\n",
    "\n",
    "print(\"We should set n_components to: \", wanted_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(X_train, X_test, y_train = y_train, y_test = y_test, verbose = False, scale = False, run_PCA = None, title = ''):    \n",
    "    print(\"\\n=======================================\")\n",
    "    print(title)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if run_PCA:\n",
    "        pca = PCA(n_components=run_PCA)\n",
    "        _ = pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "    DTC = DecisionTreeClassifier() \n",
    "    RFC = RandomForestClassifier(n_estimators=250, n_jobs=-1)\n",
    "    ETC = ExtraTreesClassifier(n_estimators=250, n_jobs=-1)\n",
    "    XGB = xgboost.XGBClassifier(n_estimators=250, n_jobs=-1)\n",
    "    GBM = lightgbm.LGBMClassifier(n_estimators=200, n_jobs=-1)\n",
    "#     RFC = RandomForestClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     ETC = ExtraTreesClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     XGB = xgboost.XGBClassifier(n_estimators=250, random_state=42, n_jobs=-1)\n",
    "#     GBM = lightgbm.LGBMClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "    list_of_CLFs_names = []\n",
    "    list_of_CLFs = [DTC, RFC, ETC, XGB, GBM]\n",
    "    ranking = []\n",
    "\n",
    "    for clf in list_of_CLFs: \n",
    "        _ = clf.fit(X_train,y_train)\n",
    "        pred = clf.score(X_test,y_test)\n",
    "        name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "        if verbose:\n",
    "            print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "        \n",
    "        ranking.append(pred)\n",
    "        list_of_CLFs_names.append(name)\n",
    "\n",
    "    # drop any subpar classifier \n",
    "    best = np.max(ranking)\n",
    "    avg = np.sum(ranking)/len(ranking)\n",
    "    variance = best - avg \n",
    "    to_remove = ranking - avg + variance\n",
    "    to_remove_alt = ranking - best + variance\n",
    "    # print(list_of_CLFs_names)\n",
    "    # print(to_remove)      \n",
    "    # print(to_remove_alt)\n",
    "\n",
    "    ranking = np.array(ranking)[to_remove > 0]\n",
    "    list_of_CLFs = np.array(list_of_CLFs)[to_remove > 0]\n",
    "\n",
    "    eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, fit_base_estimators=False, voting='soft')\n",
    "    eclf.fit(X_train, y_train)\n",
    "    pred = eclf.predict(X_test)\n",
    "    probas = eclf.predict_proba(X_test)\n",
    "    acc = eclf.score(X_test, y_test)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Acc: %0.5f for the %s\" % (acc, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "#     print(\"F1 score: \\t\\t\", round(f1_score(y_test, pred, average='micro'), 3))                # 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"Log loss (categorical cross entropy): \\t\", round(log_loss(y_test, probas), 3)) # -log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "\n",
    "    if verbose:\n",
    "        skplt.metrics.plot_roc(y_true=y_test, y_probas=probas)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "No Scaling, no PCA, Dim:274\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.95604 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.179\n",
      "\n",
      "=======================================\n",
      "Scaling, no PCA\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.94505 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.174\n",
      "\n",
      "=======================================\n",
      "No scaling, PCA:2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.89011 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.359\n",
      "\n",
      "=======================================\n",
      "Scaling, PCA:2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.85714 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.494\n"
     ]
    }
   ],
   "source": [
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = False, title= \"No Scaling, no PCA, Dim:\" + str(X_train.shape[1]) )\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = True , run_PCA = False, title= \"Scaling, no PCA\")\n",
    "\n",
    "# benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = wanted_n_components, title= \"No scaling, PCA:\" +str(wanted_n_components))\n",
    "# benchmark(X_train, X_test, y_train, y_test, scale = True, run_PCA = wanted_n_components, title= \"Scaling, PCA:\" +str(wanted_n_components))\n",
    "\n",
    "# benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 30, title= \"No scaling, PCA:\" +str(30))\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 2, title= \"No scaling, PCA:\" +str(2))\n",
    "benchmark(X_train, X_test, y_train, y_test, scale = True, run_PCA = 2, title= \"Scaling, PCA:\" +str(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a autoenoder to 'beat' the proformance of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kali\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 324 samples, validate on 37 samples\n",
      "Epoch 1/250\n",
      "324/324 [==============================] - 0s 1ms/sample - loss: 0.8655 - val_loss: 0.9036\n",
      "Epoch 2/250\n",
      "324/324 [==============================] - 0s 448us/sample - loss: 0.8329 - val_loss: 0.8848\n",
      "Epoch 3/250\n",
      "324/324 [==============================] - 0s 429us/sample - loss: 0.8099 - val_loss: 0.8879\n",
      "Epoch 4/250\n",
      "324/324 [==============================] - 0s 426us/sample - loss: 0.7974 - val_loss: 0.8786\n",
      "Epoch 5/250\n",
      "324/324 [==============================] - 0s 457us/sample - loss: 0.7900 - val_loss: 0.8820\n",
      "Epoch 6/250\n",
      "324/324 [==============================] - 0s 444us/sample - loss: 0.7765 - val_loss: 0.8829\n",
      "Epoch 7/250\n",
      "324/324 [==============================] - 0s 426us/sample - loss: 0.7735 - val_loss: 0.8812\n",
      "Epoch 8/250\n",
      "324/324 [==============================] - 0s 420us/sample - loss: 0.7700 - val_loss: 0.8830\n",
      "Epoch 9/250\n",
      "324/324 [==============================] - 0s 426us/sample - loss: 0.7660 - val_loss: 0.8885\n",
      "Epoch 10/250\n",
      "324/324 [==============================] - 0s 420us/sample - loss: 0.7582 - val_loss: 0.8806\n",
      "Epoch 11/250\n",
      "324/324 [==============================] - 0s 534us/sample - loss: 0.7588 - val_loss: 0.8924\n",
      "MSE: 280.76\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512,  activation='elu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128,  activation='elu'))\n",
    "\n",
    "model.add(Dense(2,    activation='linear', name=\"bottleneck\")) # elu activation yeilds [-1, -1, NUMB]\n",
    "\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(128,  activation='elu'))\n",
    "model.add(Dense(512,  activation='elu'))\n",
    "model.add(Dense(X_train.shape[1],  activation='elu'))\n",
    "model.compile(loss='mean_squared_error', optimizer = Adam(0.0005))\n",
    "\n",
    "\n",
    "ES = EarlyStopping(patience=7, restore_best_weights=True)\n",
    "history = model.fit(X_train, X_train, batch_size=4, epochs=250, verbose=1, validation_split = 0.1, callbacks =[ES])\n",
    "print(f'MSE: {np.sum(((X_train-model.predict(X_train))**2).mean(axis=1)):.2f}')\n",
    "\n",
    "encoder = Model(model.input, model.get_layer('bottleneck').output)\n",
    "embedding = encoder.predict(X_train)  # bottleneck representation\n",
    "\n",
    "\n",
    "#Acc: 0.85714 for the EnsembleVoteClassifier | PCA(2) | Log loss: 0.487\n",
    "#Acc: 0.89011 for the EnsembleVoteClassifier | AE(2) | Log loss: 0.498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 2)\n",
      "[-1.3598827  -0.15723611]\n"
     ]
    }
   ],
   "source": [
    "X_train_dimRect_via_AE = encoder.predict(X_train)\n",
    "X_test_dimRect_via_AE = encoder.predict(X_test)\n",
    "print(X_train_dimRect_via_AE.shape)\n",
    "\n",
    "print(X_train_dimRect_via_AE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "PCA: 2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.85714 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.486\n",
      "\n",
      "=======================================\n",
      "Autoencoder's embedding dim: 2\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Acc: 0.87912 for the EnsembleVoteClassifier\n",
      "Log loss (categorical cross entropy): \t 0.327\n"
     ]
    }
   ],
   "source": [
    "benchmark(X_train, X_test, y_train, y_test, scale = False, run_PCA = 2, title= \"PCA: \" + str(2)) # PCA(2): 89%\n",
    "benchmark(X_train_dimRect_via_AE, X_test_dimRect_via_AE, y_train, y_test, scale = False, run_PCA = False, title= \"Autoencoder's embedding dim: \" + str(X_train_dimRect_via_AE.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 92% with PCA - 0.99\n",
    "# 94% without PCA NOR Standard Scaler \n",
    "# 94% with only Standard Scaler \n",
    "\n",
    "## best out of 5 tested\n",
    "# Acc: 0.82418 for the LGBMClassifier on 2D VIA AE - few epochs \n",
    "# Acc: 0.79121 for the LGBMClassifier on 2D VIA AE - many epochs\n",
    "# Acc: 0.81319 for the LGBMClassifier on 2D VIA AE - many epochs & Dropout(0.4)\n",
    "# Acc: 0.85714 for the LGBMClassifier on 2D VIA AE - many epochs & Dropout(0.4) & Smaller batch_size (128 -> 16)\n",
    "# Acc: 0.86813 for the LGBMClassifier on 2D VIA AE - many epochs & Smaller batch_size (128 -> 16);  Acc: 0.90110 for the DecisionTreeClassifier\n",
    "# Acc: 0.89011 for the ExtraTreesClassifier        - via chance??  \n",
    "# Acc: 0.93407 for the XGBClassifier               - many epochs & Dropout(0.4) & Smaller batch_size \n",
    "\n",
    "# Acc: 0.83516 for the LGBMClassifier on 2D via PCA\n",
    "\n",
    "\n",
    "# output of PCA(2)\n",
    "# Acc: 0.75824 for the DecisionTreeClassifier\n",
    "# Acc: 0.86813 for the RandomForestClassifier\n",
    "# Acc: 0.83516 for the ExtraTreesClassifier\n",
    "# Acc: 0.86813 for the XGBClassifier\n",
    "# Acc: 0.83516 for the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dimRect_via_AE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dimRect_via_AE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.60267711e-01,  2.21744515e-02, -1.10475481e-01, -2.22988129e-02,\n",
       "       -2.53815770e-01, -2.51095891e-02, -7.51948357e-03, -1.33945823e-01,\n",
       "        1.09425224e-02,  5.21122575e-01, -1.54913068e-01, -6.88770413e-02,\n",
       "       -6.81294799e-02,  2.21823603e-01, -6.00534678e-03, -1.97968900e-01,\n",
       "       -4.51829433e-02, -1.60186887e-02, -1.21860445e-01,  1.08675649e-02,\n",
       "       -1.06098354e-01, -2.91204453e-02,  2.47066095e-01,  2.83731252e-01,\n",
       "       -4.22552586e-01, -1.10721231e-01, -1.58872008e-02,  3.89564633e-01,\n",
       "        1.98622867e-02,  1.11357495e-01,  3.14780384e-01, -2.98141241e-02,\n",
       "       -2.78887153e-02,  5.46261482e-03,  5.14480807e-02,  3.74684513e-01,\n",
       "       -2.71954656e-01, -1.17337525e-01, -3.03967595e-02,  3.85224164e-01,\n",
       "        1.04978561e-01,  1.37246167e-02,  2.19013914e-02,  6.65135868e-03,\n",
       "       -5.37996292e-02, -7.47852325e-02, -1.18792534e-01, -3.32733929e-01,\n",
       "        2.52318710e-01,  3.40282209e-02,  1.39769837e-02, -1.81501746e-01,\n",
       "       -8.51251483e-02, -1.07250690e-01,  2.86938995e-01,  2.73859221e-02,\n",
       "       -7.22833276e-02,  1.22395217e-01,  1.68290995e-02, -2.94727862e-01,\n",
       "        3.04116100e-01, -3.86977792e-02,  7.63284042e-05, -2.69038022e-01,\n",
       "        9.03237611e-03, -2.65567899e-02, -3.15495133e-02, -7.74025917e-03,\n",
       "       -6.70641065e-02, -5.25208712e-02,  1.30327223e-02,  3.27755243e-01,\n",
       "       -3.93388510e-01, -9.37491655e-03, -9.58284736e-02,  3.88512760e-01,\n",
       "       -1.05581582e-01, -8.33935738e-02, -5.19841909e-03,  1.75055996e-01,\n",
       "       -8.61072540e-02,  3.37710045e-03, -2.48659849e-01,  2.00864464e-01,\n",
       "        3.33697677e-01, -4.18266058e-02, -1.43991292e-01, -1.63233280e-03,\n",
       "       -2.96476901e-01,  7.77319372e-02,  4.14821506e-02, -6.68618083e-02,\n",
       "       -4.54556942e-03,  1.24014448e-02, -2.57407904e-01,  1.89197704e-01,\n",
       "        2.14928478e-01, -1.31697059e-02, -1.35808647e-01,  3.87044586e-02,\n",
       "       -8.11143517e-02, -1.49721801e-01,  2.80695260e-02, -1.73138976e-02,\n",
       "       -3.73384356e-02,  9.60375182e-03, -3.00168812e-01,  3.37967753e-01,\n",
       "       -2.83331871e-02, -3.55900526e-02, -1.81726813e-02,  2.22426564e-01,\n",
       "       -1.11803412e-01,  6.13522120e-02, -3.28481793e-02,  4.13364321e-02,\n",
       "       -1.74875617e-01, -6.10244274e-02, -1.48893237e-01,  2.77033120e-01,\n",
       "       -2.62262225e-01,  4.24388386e-02, -1.51073933e-02,  3.29982758e-01,\n",
       "       -1.02023423e-01,  4.87383790e-02,  3.52609903e-04,  8.09341855e-03,\n",
       "        1.54995114e-01, -1.63811684e-01,  1.84520140e-01,  7.09149241e-03,\n",
       "       -3.39316666e-01, -1.53243363e-01,  2.48883814e-02,  3.31198499e-02,\n",
       "        2.25059204e-02, -4.90899682e-02,  3.21997590e-02, -2.10340858e-01,\n",
       "        9.13256779e-04, -5.26279211e-03,  3.00705045e-01,  1.02941684e-01,\n",
       "       -3.18828404e-01,  3.23490351e-02,  3.84498388e-03,  2.03782812e-01,\n",
       "        1.91245042e-03,  7.25183450e-03, -1.52281702e-01,  6.23811223e-03,\n",
       "        1.07420608e-02, -1.75465345e-02,  1.61392778e-01,  1.07153647e-01,\n",
       "       -5.83291054e-02,  9.88091454e-02,  1.42716512e-01,  4.72225761e-03,\n",
       "       -8.38460922e-02,  2.17066720e-01, -7.91477561e-02,  1.65432185e-01,\n",
       "       -1.67834401e-01, -1.94335401e-01,  7.00403571e-01,  4.92633015e-01,\n",
       "       -8.63239765e-02,  1.51578575e-01,  1.00744292e-01,  1.50020987e-01,\n",
       "        6.82385027e-01,  6.26111329e-01, -3.08084965e-01,  2.32648492e-01,\n",
       "        4.72713202e-01,  4.35948551e-01, -7.98055530e-02,  8.82709250e-02,\n",
       "        2.83115387e-01, -1.41940713e-01,  6.29947603e-01,  4.93471861e-01,\n",
       "       -1.39923096e-02, -9.49935913e-02, -3.52524281e-01, -2.10122585e-01,\n",
       "        5.32740094e-02, -3.01386118e-02, -1.75697207e-02, -1.86261415e-01,\n",
       "       -3.50574970e-01, -3.84627819e-01,  2.63749003e-01,  6.49430156e-02,\n",
       "       -3.77946675e-01, -1.71339035e-01, -2.71075368e-02,  2.40649283e-02,\n",
       "       -7.88137317e-02,  2.24466071e-01, -3.74078929e-01, -2.13841319e-01,\n",
       "       -2.51486540e-01,  2.48871488e-03,  6.75561130e-01,  4.77543563e-01,\n",
       "       -7.04722404e-02,  3.33804190e-02,  1.47347674e-01,  9.60807428e-02,\n",
       "        7.19190419e-01,  6.64850295e-01,  4.63315845e-03,  2.51330018e-01,\n",
       "        1.02622313e-02, -2.27176070e-01, -6.94640279e-02,  1.04624264e-01,\n",
       "        8.30060989e-02, -7.72578716e-02, -1.02682054e-01, -9.45715904e-02,\n",
       "        3.25368866e-02,  1.92680195e-01,  1.82370260e-01, -1.99512243e-01,\n",
       "       -3.53891850e-02,  1.33914575e-01, -2.27330327e-02,  2.27471069e-01,\n",
       "        5.77084422e-02,  1.29225254e-01,  1.03826644e-02,  1.71908647e-01,\n",
       "        2.26048648e-01, -3.07554603e-02, -5.55522442e-02,  6.94133490e-02,\n",
       "       -1.64308548e-02,  1.73383936e-01,  2.79263318e-01,  3.61235619e-01,\n",
       "       -2.19444156e-01,  1.62245497e-01,  5.30425310e-01,  2.67145276e-01,\n",
       "        2.02911627e-02,  4.75949273e-02,  7.17352256e-02,  1.59097940e-01,\n",
       "        5.63516498e-01,  4.95669723e-01, -2.70784199e-01, -6.37775660e-02,\n",
       "        5.74088335e-01,  4.05626476e-01, -8.41364861e-02, -1.92309022e-02,\n",
       "        2.18614172e-02,  2.43391767e-01,  6.19496524e-01,  5.81264436e-01,\n",
       "       -2.00599551e-01, -2.32410073e-01,  5.19692600e-01,  3.85221213e-01,\n",
       "       -5.74815273e-03, -8.37826729e-03,  2.45772973e-02,  1.68455601e-01,\n",
       "        4.18395698e-01,  5.25255024e-01], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.75670767379927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much faster \n",
    "mses = ((X_train-model.predict(X_train))**2).mean(axis=1)\n",
    "np.sum(mses)\n",
    "\n",
    "# count = 0\n",
    "# pred = model.predict(X_train)\n",
    "# for i in range(361):\n",
    "#     for j in range(X_train.shape[1]):\n",
    "#         count += (X_train[i][j] - pred[i][j])**2\n",
    "# count /= X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
