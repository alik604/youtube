{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning in one notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXwAoGsvtlvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# run later, causes issuse with malplotlib \n",
        "# from IPython.core.interactiveshell import InteractiveShell # multiline output, so `x` does `print(x)`\n",
        "# InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMlZEhnwttgZ",
        "colab_type": "text"
      },
      "source": [
        "Read more on the basics to [NumPy - 'C style arrays in python'](https://numpy.org/doc/1.18/numpy-user.pdf#page=11) | [Linear Algebra](https://docs.scipy.org/doc/numpy/reference/routines.linalg.html) \n",
        "\n",
        "Read more on [Pandas - 'excel in python'](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python) | [Docs](https://pandas.pydata.org/docs/getting_started/index.html#intro-to-pandas) | [Cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
        "* 2D Arrays, `df.plot()` \n",
        "\n",
        "Read more about [SciPy](https://docs.scipy.org/doc/scipy/reference/#tutorial)\n",
        "* Calculus, Optimization, Signal processing, FFT, statistics\n",
        "\n",
        "Read more on [MatPlotLib - 'ugly but functional plots'](https://matplotlib.org/3.2.1/tutorials/index.html) | [Docs 3rd party](https://realpython.com/python-matplotlib-guide/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gTUiShAttqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5ac4250c-4d4d-42bd-f69e-864850417d9c"
      },
      "source": [
        "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "# output = []\n",
        "print('Numbers:', numbers)\n",
        "\n",
        "for number in numbers: \n",
        "  number = number * number \n",
        "  # output.append(number)\n",
        "\n",
        "print('Numbers^2: ', numbers)\n",
        "# print('Output:  ', output)\n",
        "# numbers = output\n",
        "\n",
        "# or \n",
        "\n",
        "numbers_list_comprehension = [number**2 for number in numbers]\n",
        "print('Numbers^2 with list comprehension syntax: \\n\\t   ', numbers_list_comprehension)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Numbers^2:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Numbers^2 with list comprehension syntax: \n",
            "\t    [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdhENmRttttg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3890784d-86a4-46ad-90e0-a06ca3baf72b"
      },
      "source": [
        "# print(len(numbers)) # 10\n",
        "# print(range(5))     # range(0, 5)\n",
        "\n",
        "for idx in range(len(numbers)): \n",
        "  numbers[idx] = numbers[idx] * numbers[idx]\n",
        "print('Numbers: ', numbers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers:  [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC6h2slfvP7d",
        "colab_type": "text"
      },
      "source": [
        "This is the \"C style for loop\". \n",
        "\n",
        "while this first is a \"for-each loop\", it is seen in other languages too, it is [sometimes faster](https://stackoverflow.com/a/256861/5728614)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNlTd7bvahL1",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "len([1,2,3,4,5])+1 \n",
        "\n",
        "len([1,2,3,4,5] + 1) # error... less obvious len(myList+1)\n",
        "# error is suppressed pandas, be careful\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbFLAh-4weE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "be7942de-9b18-4dee-ff94-257f261c6f8b"
      },
      "source": [
        "n = [1,1,1,1,1,2,2,2,2,2,3,3,4]\n",
        "print(set(n), ' remove duplicates')\n",
        "print(len(set(n)), '\\t      unique elements')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 2, 3, 4}  remove duplicates\n",
            "4 \t      unique elements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CN9A4OtuHcx",
        "colab_type": "text"
      },
      "source": [
        "## Numpy lets us do vectorized operations on the CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx89FQUHttwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2bb45607-92a6-44df-81c7-8d66922a9ad3"
      },
      "source": [
        "try: \n",
        "  print(numbers/10) # Python list \n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Error: unsupported operand type(s) for /: 'list' and 'int'   \\nWe cant divide a list by a number\\n\")\n",
        "\n",
        "\n",
        "print('However, we can in NumPy:', np.array(numbers)/10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsupported operand type(s) for /: 'list' and 'int'\n",
            "Error: unsupported operand type(s) for /: 'list' and 'int'   \n",
            "We cant divide a list by a number\n",
            "\n",
            "However, we can in NumPy: [ 0.1  0.4  0.9  1.6  2.5  3.6  4.9  6.4  8.1 10. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WF65kGIttz4",
        "colab_type": "text"
      },
      "source": [
        "for lists and NumPy, [Python List Comprehension syntax is much faster](https://www.programiz.com/python-programming/list-comprehension) but less versatile.\n",
        "\n",
        "Othen its faster to apply a [Lamba](https://towardsdatascience.com/apply-and-lambda-usage-in-pandas-b13a1ea037f7) \n",
        "\n",
        "C++ syle programing is often a 'bad' way to do things\n",
        "\n",
        "<img src=\"https://i.imgur.com/FPbPsLO.png \" alt=\"drawing\" width=\"300\"/>\n",
        "\n",
        "Lets Go over\n",
        "\n",
        "*   Pandas\n",
        "*   Numpy\n",
        "*   CuPy\n",
        "\n",
        "A DataFrame is a construct for a 2D array (Matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB-Vx88mtt3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#hide prints\n",
        "\n",
        "!pip install yfinance\n",
        "import yfinance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47SyPIi0tt6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "7d3c31ae-199b-48a0-e37d-6bdf15be712e"
      },
      "source": [
        "df = yfinance.download(\"t.to\") # T is AT&T\n",
        "# df.tail(5)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995-01-12</th>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.8450</td>\n",
              "      <td>5.9075</td>\n",
              "      <td>2.139365</td>\n",
              "      <td>394400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-13</th>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.8125</td>\n",
              "      <td>2.104961</td>\n",
              "      <td>76000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-16</th>\n",
              "      <td>5.8125</td>\n",
              "      <td>5.8450</td>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.8125</td>\n",
              "      <td>2.104961</td>\n",
              "      <td>70400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-17</th>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.6875</td>\n",
              "      <td>5.7500</td>\n",
              "      <td>2.082326</td>\n",
              "      <td>112400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-18</th>\n",
              "      <td>5.6875</td>\n",
              "      <td>5.7200</td>\n",
              "      <td>5.6875</td>\n",
              "      <td>5.6875</td>\n",
              "      <td>2.059691</td>\n",
              "      <td>60800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close  Adj Close  Volume\n",
              "Date                                                         \n",
              "1995-01-12  5.9375  5.9375  5.8450  5.9075   2.139365  394400\n",
              "1995-01-13  5.9375  5.9375  5.7825  5.8125   2.104961   76000\n",
              "1995-01-16  5.8125  5.8450  5.7825  5.8125   2.104961   70400\n",
              "1995-01-17  5.7825  5.7825  5.6875  5.7500   2.082326  112400\n",
              "1995-01-18  5.6875  5.7200  5.6875  5.6875   2.059691   60800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RLJfkHFydLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "b8cb26bb-781a-48f3-f238-517519e09a56"
      },
      "source": [
        "df.describe()\n",
        "# df.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6414.000000</td>\n",
              "      <td>6414.000000</td>\n",
              "      <td>6414.000000</td>\n",
              "      <td>6414.000000</td>\n",
              "      <td>6414.000000</td>\n",
              "      <td>6.414000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.970495</td>\n",
              "      <td>13.092584</td>\n",
              "      <td>12.864279</td>\n",
              "      <td>12.981911</td>\n",
              "      <td>9.031048</td>\n",
              "      <td>2.327247e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.245854</td>\n",
              "      <td>6.277219</td>\n",
              "      <td>6.222063</td>\n",
              "      <td>6.249906</td>\n",
              "      <td>6.686632</td>\n",
              "      <td>2.512064e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.772500</td>\n",
              "      <td>1.440000</td>\n",
              "      <td>1.525000</td>\n",
              "      <td>0.760416</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.037500</td>\n",
              "      <td>8.126875</td>\n",
              "      <td>7.950000</td>\n",
              "      <td>8.025000</td>\n",
              "      <td>3.747595</td>\n",
              "      <td>1.056550e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.225000</td>\n",
              "      <td>11.362500</td>\n",
              "      <td>11.125000</td>\n",
              "      <td>11.247500</td>\n",
              "      <td>6.194226</td>\n",
              "      <td>1.903800e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18.758750</td>\n",
              "      <td>18.940001</td>\n",
              "      <td>18.628749</td>\n",
              "      <td>18.780001</td>\n",
              "      <td>14.535185</td>\n",
              "      <td>2.913200e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27.549999</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>27.459999</td>\n",
              "      <td>27.674999</td>\n",
              "      <td>27.021269</td>\n",
              "      <td>6.230600e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open         High  ...    Adj Close        Volume\n",
              "count  6414.000000  6414.000000  ...  6414.000000  6.414000e+03\n",
              "mean     12.970495    13.092584  ...     9.031048  2.327247e+06\n",
              "std       6.245854     6.277219  ...     6.686632  2.512064e+06\n",
              "min       1.750000     1.772500  ...     0.760416  0.000000e+00\n",
              "25%       8.037500     8.126875  ...     3.747595  1.056550e+06\n",
              "50%      11.225000    11.362500  ...     6.194226  1.903800e+06\n",
              "75%      18.758750    18.940001  ...    14.535185  2.913200e+06\n",
              "max      27.549999    27.740000  ...    27.021269  6.230600e+07\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie0FU5iQGcEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file location, local or URL.... raw CSV on github. Avoid Kaggle's API  ;) \n",
        "# pandas.read_csv\n",
        "\n",
        "# hit CTRL + Space\n",
        "# df.to_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GswW7gStt9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "243afd36-7542-43e2-e769-856119033a4b"
      },
      "source": [
        "close = df.Close #  same as df['Close']\n",
        "\n",
        "print(type(df))\n",
        "print(type(close))\n",
        "print(type(close.values))\n",
        "\n",
        "assert df.shape == df.values.shape # Hence, True \n",
        "print(df.values.shape) # df.values is a quick way to get a 2d array\n",
        "print(df.values[:1]) # df.values is a quick way to get a 2d array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'numpy.ndarray'>\n",
            "(6414, 6)\n",
            "[[5.93750000e+00 5.93750000e+00 5.84499979e+00 5.90749979e+00\n",
            "  2.13936496e+00 3.94400000e+05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpcEsDY-tuAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "8564d622-8249-4d90-8eca-d8a8062575bf"
      },
      "source": [
        "# df.plot() #all columns (feature vectors) \n",
        "close.plot(figsize=(14,5))\n",
        "\n",
        "# close = close.to_list()\n",
        "close = close.to_numpy() # now we lost the time axis :'(\n",
        "close[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.90749979, 5.8125    , 5.8125    , 5.75      , 5.6875    ,\n",
              "       5.6875    , 5.6875    , 5.5625    , 5.625     , 5.78249979])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy8AAAEtCAYAAAABel8SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzddXgU59oG8HtW4m5AsBDcLWiLlRYoqdupu/ecnvarQQstpcapu526G7VTKIXi7g7Bg8ddNmvz/TG7szMr2U2yye6G+3ddvTq6+6aN7DPv+zyPIIoiiIiIiIiIgp0m0AMgIiIiIiLyBYMXIiIiIiIKCQxeiIiIiIgoJDB4ISIiIiKikMDghYiIiIiIQgKDFyIiIiIiCgm6lnyzlJQUMSMjoyXfkoiIiIiIQsjmzZuLRFFMdXeuRYOXjIwMbNq0qSXfkoiIiIiIQoggCEc9neOyMSIiIiIiCgkMXoiIiIiIKCQweCEiIiIiopDA4IWIiIiIiEICgxciIiIiIgoJDF6IiIiIiCgkMHghIiIiIqKQwOCFiIiIiIhCAoMXIiIiIqJWJHP6PDzzx55AD6NZMHghIiIiImolRFGEVQQ+XnUk0ENpFgxeiIiIiIhaico6c6CH0KwYvBARERERtRJl1aZAD6FZMXghIiIiImolSmuMAIBIvTbAI2keDF6IiIiIiFoJe/BSa7LAYhUDPBr/Y/BCRERERNRKlNU4lo1VtcL8FwYvREREREStxMmyWnnbYLIEcCTNg8ELEREREVErUF5jwkt/7ZP3jWZrAEfTPBi8EBERERG1AoVVdap9M3NeiIiIiIgoGNUa1cvEzBbOvBARERERURAqr5WS9f+R1REAYLJw5oWIiIiIiIJQWa1UJrlzShQAwGzlzAsREREREQUh+8xLSnQ4AM68EBERERFRkLIHL8kxYQCY80JEREREREGqvNaEMK0G8ZF6AICBpZKJiIiIiChYiKJjaVhFrQlxkXq0iYsAAOzPqwzUsJoNgxciIiIiohBksYroOXMBXlkoNabcl1eJxChH8PLc/L3Ye7oikEP0OwYvREREREQBtvJAISoMpgbdk1dhgNFsxVtLDgIADhZUYUCHBITpHB/xc/IYvBARERERkZ8UVBpww8cb8OB32xp0n8Fkcdq3IjU2XHXM7KHi2KI9+SioMDRsoEHAa/AiCEJHQRCWCoKwRxCE3YIg/Nt2fJYgCCcFQdhm+2dq8w+XiIiIiKh1mT53JwAgt7ja53sW7DqNZfsK5f0JLy+D0WJFVJhWdZ3oJnapM1twxxebcOMnGxo34ADS+XCNGcBDoihuEQQhFsBmQRAW2c69Joriy803PCIiIiKi1uerdUcxqGMCYsJ1WJxTAACI0Gu93OVw91dbVPtHiqTAp7TGqDpucRO9VBrMAKRlZ6HGa/AiiuJpAKdt25WCIOwF0L65B0ZERERE1BqV15gw49ddSIzS4+vbR8rHd59qen7KqMxk1b7F6hq8VNj6wUSH+TKPEVwalPMiCEIGgMEA1tsO/VMQhB2CIHwiCEKih3vuFARhkyAImwoLC91dQkRERER0xth1qhwAYDRbUWM0N/j+qjrXex6f2gvLHh6PSX3ber3W3swyOtz3mZ5g4XPwIghCDIC5AB4QRbECwHsAugIYBGlm5hV394mi+KEoilmiKGalpqb6YchERERERKHpaHE1rvtImgeoNlqw/kiJfC5c59tH8+X71BMCL1zWH3eO7YqMlGiXa51zYACg1igl+keG4MyLTyMWBEEPKXD5WhTFnwFAFMV8xfn/AvijWUZIRERERNRKPPLTDtX+S39JPVpuHNUZP2w67tNrxEfqAQCv/2MQLhlcfzZHXITe5ZjBLAUveo3g0/sFE1+qjQkAPgawVxTFVxXH2ykuuxTALv8Pj4iIiIgouOw4UYbjJTWNurdvepzb43ERepgsIk6X1+JUWa3L+SNF1ai2LQGzJ+F3TIry+n4mi9XlmMEkHdNrQ69rii8jPgvADQDOcSqL/KIgCDsFQdgBYAKAB5tzoEREREREDWG1ivISKX84WVaL/yzIwUVvr8aYF5c26jW0gjTbcfh5dZcRvVYDi1XEqBeWYPScJXKivSiKePK3XZjw8jLc/KlU2thilYIPrQ8zJyY3fV7q7DMvPi5TCyZeRyyK4ipRFAVRFAeIojjI9s98URRvEEWxv+34RbaqZEREREREQSHz8fno/eQCbD5aCtFdw5MGem3Rfry37FCTXuOjVUcAABqNgFWPTQAA/Hj3KJit6hmSj1cdBgAUVtbhi7VHAQAbc0sBOBpP6nwIXhbtyXM5Js+8tMZlY0REREREoeaVhfvk7cvfW4N5O5v+nD0pOky1X1DZsD4pzpXFOiRGIXdONoZlJLlUBXt+fg6OFFXj/DdWuryO1RaIaQTvwcfSfa7VfutMtpmXVrpsjIiIiIgopLy15KBqf8X+xrfsWLw3H8v3F7rMdIz5T8OWjjlXCVOyJ+Er3fzpBhRXG12Om21LynRaz8HLPeO7ejxnMNtmXlrjsjEiIiIiolD3w6YTjbqvzmzBbZ9vwk2fbECNU/5MndmKtYeKVce+23AMu06Wu7zOhiMl+HajVE3s45uyXM6P6e7aUsRdUYCjxdVYfVB6z/pyXh6e1NPjOYOpFVcbIyIiIiIKNclOS7wA993mvTla7AggPluTCwDInZMtH9tyrFTeLq81YdrPO3HBW6tcXueqD9bKsz9ZnZNczg/tnIjtT03C9icnyceUw22fEAkAGPfSMny74RgAR/K/O/UFNkVVdQAAEUBJtRHXfLgOS3LyPV4fTBi8EBEREVGrExWuRVbnRNWx0XMWN/h1Kg2mes8rA6KBTy/06TVjI9y3WoyP1CM+So+7xmW6nJvYO83lmC/VxtzZdbICALD2UDGqDGasPVyMoirX5WnBiMELEREREbU6BpMV3dvEYtfTk/HtHSMBAPkVdaprDuRX4kRp/f1aCivr/1BvLzusNCozWbWfW1St2td4CTpGd01xOeau5HFjgxd74YC8CgP+81cOACAsRJL3Q2OUREREREQ+uuXTDSisrEOkXouYcB1GdU3G9SM7AQAyps2Tyyaf99oKnF1P0r0oirj7q82qY9/cMUK1X2uUkt/LahxBzp7TFfJ2XrkB419eJu9fODDd6/jHdncNXk6Xuzau9FYtrF18BEZmui5RqzU5Aq5VB4p8eq1gERqjJCIiIiLykb08sFXR22Vy37by9ooDRSiucszC7D7lmmAPAHP+zJG3B3SIxwc3DJVnRUZ0kYKCqjppWZmyull5rUlOincup/zsJf28jl8QBOTOyVbl1pwqk4KXib0cy8diwt0vP7NLiw1HuE7rctxodvSUKa+Vxq+vp3JZMGHwQkREREStUomizHCk3vEhPreoWjXj8sWao27v/2DFYXn793+erQqAPrwhS/W6abHhAIAwW/nhAtsStdIaR85M7pxstyWR6/PT3aMw//4xmHP5AIzvmYre7eLkcxF6Lx/lBQEipOpiM37diVLbf486s9Xl0lApm1x/uEZEREREFKJGKnJPerSNRWZqNA4XVuOp33erriutcc1rOVhQWe9rx0fp0SkpCmW2mYufNkulmD+4YShu+XQj8isN6JgUiZs+2dCkryErw7Hs67NbhuPNxQfkfcFLk0r72V4zFwAAFu8tQN/0OJTVuBYhCOeyMSIiIiKiphFFEduPl2Hz0VKYLa4zBu6uB4CLB6Xj2hGd5ONxEXos/r9xbu9ZuEcqE5z17CJkTJuHkmojzn11hXx+/v1j3N53rKQGv207BQA4UFAFAEiPl0oa51cYcMk7q+Vrd8ya5PoCjWBf8vXvid29Xrsvr1LVnPN0uQF/7y1QXZMQJc0EhcrMS2iMkoiIiIjOSC/8mYOL31mNy99bg25P/CkfX32wCBnT5uHr9eolX/bSxV1TY1xey3mmYmCHeGgEoFNSFADI5YJv/GS9fM3ce0ahT3oc6mOyBVVJ0WFoEyctH8uvqMP2E45cmriIhi0X82S5LRjxVG5ZSZmY70lNna1hJWdeiIiIiIgaz2i24kNF3onS27YE+Rm/7lIdN9uCF09lhLMHtJO3h3ROxPieaYiL1MkzNoCjDwoA9Gsf73F8903oCgDobguqRmUmIz5SjzCdBvkVjkT9PbMne3yNhjrbVonsyqEdm/Q608/vhYEdE2C0BV5M2CciIiIiaoIeM/50OTbl9RUoqqrD2sPFAADRqf1JrVGaSYgKc62yBQA6RVATF6FHTLgO1XUWt0nsz13az221Lru2cRGq/dHdkiEIAtrGRWBTbol8PCrMf2nmD0/qie1PTkJ8VNNmcsJ1Gmw/XqbaDwWhMUoiIiIiIgA5eZW47N01qmODZi/EXltvld+2nQQgLeFy58kL+sjbI7okwWSx4khRtZzUfufYTDwyuSeeu7QfrhvRud6xJESp30OvkT5al1YbseWYFBi8cfUgX780n2g1QpMDFwDonBKt2u+S4rrMLhix2hgRERFRK7M/vxKXvrMaX94+An3axSFC73n2IBTER+rRu10s1h2WZjOOldSozpfVmPDcvL1YdbBIPtbRlsfiLDkmXN6Oi9SjuEpdaexwYTU+uinLp3E5/3fV2ZZeVdaZ5WN9veTLBEr3NHWw4mmZXbDhzAsRERFRiLA3FPRm8d4CVBstuOzdNeg1cwFeXbivmUfmfz9sPA4AaBMXji0zz5MDF0+UgQsADOyQ4PU9wnQauS+L3ctXDvB5jM5LrU6XG1yuaeO0tCxYdEh0H9wFOwYvRERERCHgh43HMfDphXhxQY7Xa51LCr+p6P4eKh6duwMAcN2IztBqBNVyL7tvbh/hcmxy3zbYOWtSvTMJXVMdS6ZEqJNmnJeC1UcZvOi1Aq4Y2kF1fkZ2b8T6qcqYP11nKyH91W0jEKHXYESXJC93BA8uGyMiIiIKYmsOFaGi1oy3l0oByLvLDuHRKb3qvUe5bMmd+77egkOFVVjwwFi/jbOhao0WvPTXPpgsViRFh6FrWgz0GgHn92+HRba+KwCQYlvmdevZXTCuZyoSIvUY+uzfuPWsLhiZmYyBHRNUief/GNbRa8CQFhuBQ4XV0GkEdEmJxuqDUvL/Jzf7tlzMzlbYDNn92+Gd64bIx7+6bQTWHCrC7WMyG/R6LeHAc+dDaysZfXb3FOQ8c36AR9QwDF6IiIiIgti1/5V6jviakyCKosfywnbzdp4GAOSVG9A23j/Lmi5/bw2iwrS4KqsjureJQZReh07JnpcmfbE2F5+sPuJyPHdONrYeK5X32ydGytv23i25c7LlY7/ddxaufH8NNuaWYmCHeIzvkeZ1rG9dOxgLduUhMzUGM7L7YHyPNJzbp40vX6ZKVkYiHji3O24Z3UV1/OzuKXJJ42ATKv1cPGHwQkRERBQkft16EidKa/DPc1y7p9ubLyr3a00WxISrP879svWkz++382S5X4IXo9mKzUelgGPlAUfuiTLIcJYWF+7xnL088dMX9cVYH4KAjbnSe9cYLdD4EOSlxITj+pFSJbEIvbZRgQsgBQIPnNujUfdS44R26EVERETUijzw/Ta8vHB/vdfYO6vf9eVm9HvqL5fzR4qq5e3BnaSk9fhI98uo7vhiU2OHqmIwu+/kbg+4RFHETkW3eemY+9cSRSkoC9NqcNPoDAiC92DEnsPyrmLpFrVODF6IiIiIgszfipwPZ1V1ZoiiiL/3Stc4z8jYk8hnZPfG3LtH4/qRnVBea5KDB6vi+uF+StQ+//WVbo//tPk4/u+HbXj97wO48O1V2HHCkZtiMLk2hQSAro/PR1FVHSI9NJl05+1rh+CpC/uge5vYhg38DPLpzcOw+KFxgR5GkzF4ISIiIgoyt3uYERnTPQWiKC2Psqs1qWc93rJVFrt9TCY0GgF7TknNGy98exVu/WwjCirr5Gs7+qFc7vbjZThZVuv23GNzd+LnLSfxxuIDAIA/dki5NqsPFuGnzVIp5J/vHa26xyoCP20+gX7tfe+P0rtdHG45q4v3C89g6QmRcs5QKGPwQkRERBQi4mxVtN5ffkg+9vTvu+XqXKIoos6sntFQNmVcklOAqz5YK+9brO5nPxpiX16lz9d+uOIwymtNuO6j9XIH+kEdEvDHv852ufbxqb2bPDZyCJUmlN4weCEiIiIKQv1n/aXKXwGAcL300e0tRd+WHzefwB1fbELGtHnoMn2+y+tonXJGlN3pzVYRVXVm1HnIWbErqqrD6XL3sytxtnyaa4Z3BAB0SorCy1cO9PhaZTXqjvYajYB+7eNx5IWpiNA7Ppr2bhucnelDlb+qygUaq40RERERNYPqOjPWHCrGeY2sZFVpMOPDFYdUx5w7uvtCU88tZouIfk/9hUEdE/DrfWd5vC7r2b8BuK8eZrI1xLzlrC5IiArDRQPTcbCgyuNrjXtpmby97OHx8rYgCHIeTHSY1qeqYeQ756p0oYozL0RERETN4LG5O3DHF5vq/SCv5G7249sNUl5Ipq2a1oAOCT691rm9Hb1O6qvWZa8Stk3R5LE+RrPrMjODLecmUq/FY1N6oXe7OOgUgUdClB5ZnRNd7rt+ZCd0SlLn3Dx0Xg/otQJ2PT3Zp/HQmYfBCxEREVEz2G1LlHf3gd+dKoPZ47l/TuiG3DnZ6FxP00elhyf3lLcjdO6rdvVvH49l+wp9ej27VQcd1xdUGjB38wm8uURKxk+KDpPPtVEsUdr25CT8dM9o3OqUUP/Mxf1cZlf+NbE7Djw31afyyHRmYvBCRERE5GdLcvLlfJVDhb7NvFTVeQ5eLh7UXtpQVEW+c2wmXrisv9vro8McS4SeyO6Nm0dnqM6/f/0Q6LS+BQg/bDwubxdVSfkqdWYLhj+3GA/9uB3HS6RcmGjFsqQhnVxnWowW9cwSAxRqDAYvRERERH6m7DL/r2+3orqewMRu3eFiAMCEnqku55wrRY3MTMLjU3vj6mEd3b6WMpBIig7DrIv6qs5P7tsWeq36Y6CnMT46d4e8XWmbHVpzsNjTlyH76MYsLHpwrLyvUyTfPDqlp7tbiLxqHZk7REREREGkg1P/lCU5BbhwYHq99zw2dycAYHiXZCz1sJzL/roTeko5LcrZi8QoPUprTACA6HDXpWIvXzkQcRE6nNenDQRBkAMRu9IaoyrocRap1+JIkTSLtMPW8LI+5zoVKkhPkJaSPXNxX9wwKsPr/UTuMHghIiIi8rONR0pU+x0SI32+d0q/tvjPghwAwC/3jkb7BMe9nZKjsPGJc5ESE+Zy39rpE9Fr5gIAQJjWdXHNFUM7qPb3nq5Q7XvLzenXPg7786XgpdSp3HG6D2V4bx7dBXqtBlcP7+T1WiJPuGyMiIiIyM8W7M5T7Ts3jqxPaqyjqeTgTolIi4twOe+cLzIsIxEResdsiy/5JE9e0AcA5N4q7qqinSxz9HbRagRsOFKCD1ccwmdrclXXfX7rcK/vF6bT4JazurgsVyNqCK/fPYIgdBQEYakgCHsEQdgtCMK/bceTBEFYJAjCAdu/XTOziIiIiM4AdWYLym1LtpTeumYwAO+zGsdtjSMzkqNUZYZ9cfC58/H9naMAAMsfGe9TIAE4Gl7GRkhNJu/8crN8bt6O01hzsAjFVXUAgFeuHIh1h6XZpOfn56heJy02HN3bxDZozNQy7AFqa+JL6GsG8JAoin0AjARwnyAIfQBMA7BYFMXuABbb9omIiIjOOLd9tgkDZy8EAIiiVBIsUq9FRrLUn8XbzMv8nacBSLMbDQ1edFqNXHK4c3I0xvVwTfh3xx5QxUW4ZhHc980WXPvRehTZgpfOyVEYliE9p44Kk2Z4hmckAQAqDK5BGwWHW87KCPQQ/M5r8CKK4mlRFLfYtisB7AXQHsDFAD63XfY5gEuaa5BEREREwWzVQam6mNUqIr9C+sD/eHZvxEdKsxp3f7UZtUZHqeD8CgMGzV6IJTn5ABw9Uj69ebhcWcy5gaO/DeooNbw8v187j9fc+tkmAEBCVBheumIgAKDGaEGbuHB8e+dIAPA5WKKW1xrLUTdo0aEgCBkABgNYD6CNKIqnbafyALTxcM+dgiBsEgRhU2FhwxohEREREYWSCoMJM36Vqoa1jYuQE/UtVhFP/b5Lvm7cS0tRVmOSg4PyWmn2Ij5SD0EQ8Nktw/DT3aOadayDOyVi7+wpmNy3rddrI8O0SIxyFAmoqDVDqxGw6rEJeOPqwc05TPIDdwUcQpXP1cYEQYgBMBfAA6IoVigjOVEURUEQRHf3iaL4IYAPASArK8vtNUREREStQWmNCVuOlQEAuqXFqDrIrznk6I1iMDmWkRVX1aHCVrY4xraEa7ytFHJziwzTyrkvdvZlb0pReq2q/LJ9psi5JDQFn0UPjkV8lD7Qw/Abn8IwQRD0kAKXr0VR/Nl2OF8QhHa28+0AFDTPEImIiIiCjyiKeOTH7fhy3VH5WGmNUS5J3CVFyncZ0CEeADDQtkzLOTgY9tzfKK6qQ2y4zqUZZUtQvmdZjdFtfk5UuBY6xdP7sT1SWmRs1HTd28QiLdZ7KetQ4Uu1MQHAxwD2iqL4quLU7wBusm3fBOA3/w+PiIiIKPgYTBYUVtXhx80nMPNXx3Kw5fsKUVVnRkqMo9zxD3dJy7/m7TiNGqMZp8oNqteyisDX64+h0kOH++ZmtTqCqRs+3iAvYVMK10mzLmNt+S2zLurbMoMjcuLLsrGzANwAYKcgCNtsxx4HMAfAD4Ig3AbgKICrmmeIRERERMGl18wFcJcL/cbiA7hgQDvEKip4KfuvLN9XKC/h6dkmFvvyK5t9rN50S4uRt3eeLMdqW/EBux8VuTdf+FiGmai5eA1eRFFcBcDTHOZE/w6HiIiIKDS4SQ0BACzeW4CzuiW7PXfP11vk7fdvGIoJLy9rhpE1jCAIaBMXLldJM1uclrXZSiITBYPWU3qAiIiIKAjUmiwY3dV7TohzKeRLBqU315C8sgcuAGCyOnJeYsN9ru1E1CIYvBARERE1wc2jM3DBAHWvlK6KpVgAcM3wTqr97AHtoNUIiFQsKVMuLwuk/XnSUrZPbxmGvx8aF+DREKkxeCEiIiJqAOdqYVcM7SA3cLQb1CFBtX/5kPaq/adtCe9LHh6HXm1jAUhli4PB52ul6mlDOyeiTVzrqVJFrQODFyIiImr1couqMfm1FThaXN3ge/ecqsC+PEdi/YnSWtX5rqkxiAzT4o9/nY32CZFY9dgEl74aWRlJuHyIVEK5Z5tYuRpZu/hIXJXVEQCQHh/Z4LH5y9x7RmPWhX1Ux1pTY0NqPfhdSURERK1aWY0R419ehn35lfhm/bEG3fvB8kOY+uZKTH59BWqMZoiiiDEvLpXPd06OkmdM+rWPx+pp53hs3BgXKeWPXD5UPQtz3chOeGJqb9w0OqNBY/OnoZ0TccMo9fvrAtBzhsgbBi9ERETUqhVVOZLRP1hxuEH3vvBnjry962SFSy+Wo8U1Pr/WdSM6IyUmDFP7q/NjwnVa3DE2E2G6wH4sc26QGYiGmUTeMHghIiKiVq3W6Nox3htRFLHfqQdLVZ0JJ0qcl4xF+/ya3dJisGnGeR5nZoLBXWMz5W3BXSMbogBj/TsiIiJq1WpNFnnbuTyxJz9tPoFHftqhOnbrZ5tU+9cM74Qnsns3fYBBpLzWFOghENWLMy9ERETUqtmDlx5tYlSBTH2OFDkS+1+4rL/L+Ym90vD0RX0R08r6oJwuNwR6CET1YvBCRERErdYPG4/jpk82AAASosJg8DF4UZYI7pcej2inMsb/vTEr4DkqzaFf+zgAQHyk3suVRIHRuh4XEBERESk8Otex9KttXAQ2Hy2FxSp6TUavMTqCnDZx4UiKCUO1Ld/l/87rAU0rTWb/1znd0TkpGhcNSg/0UIjcan2PDIiIiOiMZbWK+HDFIRQrKozZjchMgsUqYsuxUq+vU11nhiAA25+ahLS4CAztlCifu39id7+OOZhE6LW4alhHROiDo2EmkTMGL0RERNRqLD9QiOfn5+DZeXtVx6ef30uu8rXqQBEsVtHt/V+uO4pXF+1HtdGMmDCdvHzqmUv6AQCecmrkSEQti8vGiIiIqNVYub8IABAbIX3EiYvQoUtKNO4Yk4ljJVJPljcWH4BOI+BfbmZQZv66CwBwXp82iAp3zD7ERuiROye7uYdPRF4weCEiIqJWw17qd/HeAnyxdh4AoE96PDQaQRWM7DxZXu/r7M+vRL/0+OYbKBE1CoMXIiIiajW2HZfyWU6WOZpJpsdLlcOiwxwfe7xVCjtaXMOKW0RBiMELERERtQoH8itxqLDa5fhVwzoCACIVSejd02JV14iiiN2nKlTHdpyof3aGiFoeE/aJiIioVfhu43G3x5OiwwBAVd44JkL9/Pb37adwwVurVMfG9kj18wiJqKk480JEREStQpXBrNr/5d7R0Gs10Gtdn9WKorramLvO8h/flOXfARJRkzF4ISIiopBXYzSjxiQ1llzy0DgUVtZhsKI3izOzh1LJSu6CHiIKLAYvREREFPL6PfUX7PFIZmoMMlNj6r2+uk49S+Op7wsRBRc+UiAiIqKQ52vs8dVtIwAAby05qDquDF5uPasLFjwwxm9jIyL/4cwLERERnTHO7p7i9nhRVZ28/dj5PRGu07q9jogCizMvRETkVztOlOHxX3ZiaU4B8soNXI5DfmVPtD9YUImHf9yOGqNZlXyfmRrdqNf9Yu1ReZuBC1Hw4swLERH5TVmNERe9vRoA8M36Y/Lx3DnZgRoStTKXv7cGeeUGRIXrcLCgCj9tPqE6/90dI72+xpjuKVh5oMjtuSMvTPXLOImoeTB4ISIilYW786DTCjinV5sG3/vZmlz/D4jOOJe8sxqxETq8f/1QRIc7Pqq89FcOthwrq/fetLgIr6/fOTkKe06FuT0nCILb40QUHLhsjIiIVO78cjNu/WxTg+7JmDYPGdPmIT5S30yjojNFndmCbcfLsPJAEfo+9RfMFqt87p2lh+q9d/bFfX16D40gwKJYarYxt6RxgyWiFsfghYiI8M7Sg8iYNg8frqj/w6E3ry7a7/Z4r5l/Nul16czx29ZTqn2Tpf6cqfE9U3Zm+LYAACAASURBVAEAwzOS8I9hHX16D40gwGrLxVq6rwBXvr8WAJAQxeCbKNhx2RgREeGlv/YBAJ6fn9Ok16k0mKHTCC4NAA0mq4c7iBxEUURkmDpZ3mi2Ir/CgAqDSXV85gV9MKJLElJiwvH20gN48oK+CNP59kxWqxFQYTAjY9o81fGyGpOHO4goWDB4ISKiJnGuJpYQFaYqO0vki5f+ysE7Sw+5VAt7bO4OLNid53L9Wd2S0attHADg2Uv6N+i9PFXA0zDdhSjocdkYERE1icminlVpnxjp9jplOVsiZ/Z8lsOF1arj7gIXAGjrQ2K+J6U1RrfHlzw0vtGvSUQtg8ELEdEZzjn4AIAwre9/HmqMFtV+pF597y1nZQAAjG7eh8iTO8Z0cXt89sV98et9ZyEhyn21MF+UVLsPXjJSGtcjhohaDoMXIqIz3LS5O12Ohet9//NQ5vQUu7jKiLXTz0F0mBYpMeHokBgFgHkv5Jkoiqp8lewB7XD50A6qayb3lUp3d0+LxaCOCU16P0/BCxEFP685L4IgfALgAgAFoij2sx2bBeAOAIW2yx4XRXF+cw2SiIiaz9wtUpO/rqnROGRbshOh973DeHmtOsm5uNqIdvGR2D17CkRRxDcbpGaVBpOFpZTJrbwKA4xmR3D7ypUDEaHXIkyrkWfs3r9+KPblV8p5Lk3BxHyi0OXLo7XPAExxc/w1URQH2f5h4EJEFKL6pksfBsN1WpzbOw0AkB7vez7B9xuPq/aVT7UFQUCkLRAymNTLy4gAadniqBeWAABmZPfGd3eOlIPnmRf0lq8TBMEvgQvgWML4zR0j8OLlA3D72V2w6+nJfnltImpeXmdeRFFcIQhCRvMPhYiIAiE9IRK7T1Wgqs6Mt64ZgsveWwNtA8oufWcLXt65dgh+2nwc143orDpv/yB6/cfrsfLRc/w3cAppm4+W4IeNJ/D9JkfwmxQdhpGZyfJ+9oB0rDtcgmcu6efX97YXj+jRJhaju6b49bWJqHk1pVTyPwVBuBHAJgAPiaJY6qcxERFRC2qfIFUHe/e6IYgM0yIlJgxVdeYGv86wLonIHtDO5XiELX/meElt0wZKrcrl7611OZYaG67aT4oOwzvXDfH7e9srJWsE1kYmCjWNTdh/D0BXAIMAnAbwiqcLBUG4UxCETYIgbCosLPR0GRERBYhVFJEYpUe/9vHyMV+rGlcqGgemxbpfatYpKapJ46PWIbeoGhnT5uGD5YdcmkMCwJjuKRjTPbVFxnLDSGl2MDrc99wuIgoOjQpeRFHMF0XRIoqiFcB/AQyv59oPRVHMEkUxKzW1ZX4pUXA4WFCFmz7ZgFoj17kTBTOzVYRW4/hzIAgCfO3Ics9XW7xe0y0ttpEjo9Zk4R6pX8sLf+a4Pd+QpYpN9eB5PXDkhakI1zF4IQo1jQpeBEFQrgu4FMAu/wyHWpMnf9uF5fsLseZQUaCHQkT1sFhE6BQfHAWg3qmXj1YeRsa0ecgrN2DVQenn+//O69Gg9zxWXIP5O083ZrgUopTVxNzpmNiyM3QCl4wRhSSvwYsgCN8CWAugpyAIJwRBuA3Ai4Ig7BQEYQeACQAebOZxUgiqsC0nue3zTdh7uiLAoyEiT6SZF8cHubJaE3KLa9xeazBZ8Oy8vQCAkS8slo/fMSazQe+Z/eZK3Pv1Flitvs7xUKgoqqrDyTJ1ftP6w8V4eeF+l2tjwnVY9OBY3DCyMx6Z0rOlhkhEIcyXamPXuDn8cTOMhVqZmjrHcrEjRdXo3c4/JS6JyL8sVit0Wkfwsv14GQBgY24JSquNmNS3rXxuw5ESt6+h19b/FPusbsmqJpWVtoIAmY/Pxz8ndMOY7ikYoagyRaHJYLIg69m/AQC5c7JRWm3E//2wDUv3qXNe02LDkRITjm/vGIn4KL3fq4kRUevVlGpjRPVSPsmNbEDDOyJqWWarCK2bJTRXvi9Vg/rx7lEYlpEEAIhz02Ty7nFdodPWP5EfHaZDUaU0m+Pc1PLtpQfx9tKDyJ2T3ajxU/CYo8hneXFBDt5ddsjlmqzOiXju0v7o2Za5UETUcI2tNkbklfLDTC2b0xEFLYvTsjFn9iAGAG7+dIPq3Izs3ph2fi+v75EcE47i6joAwKM/bW/kSCmYGUwWfLYmV953F7i8f/0Q/HTPaAYuRNRonHmhZhOmWEbCimNEwctb8AIAVquI3OJqlNWoZ03G90zz6T2So8NQWmNCSbURf+3Odzk/sZdvr0PB6z03wYrS57cOx7gerDpKRE3DmRdqNsrZlpNltbjwrVXYfaocAHC8pAZHiqoDNTQiUrBYRVXOy7z7z0Yvpyfjf+3OwzmvLJf3Dz0/FduePA/d0mJ8eo/kmDBYrCKu/tAxizP3nlHytpmJ+yGpxijlLp0qq8Ubiw+4nLf3U5l9cV8GLkTkF5x5oWZRUm3E/vwqef/VRVKVmew3VyF3TjbGvLgUALjGnSjADCYLDhdVq3JZ+qbHY8EDY7E0pwC3fLYRAHDP145+Lref3QVajYCEqDCf3ycpWrpW+XthaOckvHrVQDz043b5QzAFl1qjBVqNgDCd67POVQeKcP3H6/HhDUORFudoUPrbfWchLS4c0eE6xEXoMeuivi3aw4WIWjfOvFCzOOVUJlPJXWdlIgqM+77egiNF1SivMbqcm9ArDef1aeNy/IKB6Q1+n315lW6PXzakAyb2SkMNl5YGpd5PLsA1/13n9ty8nacAAPd9swWL90pLAaed3wsDOyagXXwk4iKkgJiBCxH5E4MXahYmi6Mkqq6eP1wWLhUhCpitx0qxOKcAADz2dbliaAeXY/FuKo554/yzvnb6OfJ2ZJiOwUsQ+njVEQDA5qOlAABRFDF/52n5/+WeU1L/LpNFxFtLDgJg7hIRNT8GL9Qs7OvXv7ptRL1lkkvdPO0lopZx6btrvF7Tx01/psYEL+0TI1X77eId+wt35+FIUTUbVgaZ/yjKHr/81z689Nc+3Pv1Ftz/7VYAwIlS1xn2xnxvEBE1BIMXahb2mRedVpCb0blTWs3ghSiYxUaoUyNfuXKgnL/SENeP6OzxXJ1Z+n1RxbyXgDtUWIUL3lqJX7aegFExg/720oNy6eM1h4ogiiLKnPr1AEBiI743iIgagsELNQuTRXqC6tx1e+WjE1T7pTWuf/yIKHhEKGZOx/dMxeVulpH5QqNYPvrmNYNV556/tD8AoJy/DwLqo5WHMfGV5dh1sgIPfu+5F09pjQnF1UZYrCIm9krDo1N6okebGLx85UDovTQrJSJqKlYbo2Zhtj2xc/5Dlp6gXjpiYPNKooCoM0s/e//I6ojvNx1HenyE2+si9FpseGIi4iL0fvtgOjwjSbXfJSUaAHCwoAodk6L88h7UcM/O2+ty7ImpvfHcfNfjN34sNSu9eHB7XDQwHfeO79bs4yMiAhi8UDORl41p1B92tBoBuXOyseNEGS56ezWMZqu724momZXblvz06xCPpy7qA43gubBGWqz7wKaxdE4zsn3bS3k1+/IrMYEJ3wFRVFXn9vjwLkluj+85LSXrD+2c2GxjIiJyh/O71Czu/krqCaFcNjYsw/FHLlwnLUWpY/BCFBAVtuAlPlKPqDCdanlYc5l1YR+kxIS7JHXHRegRrtMwBy6AlMHLtPN7AQCuGd4JAzsm1HtfWmx4s46LiMgZZ17I75Tr1nWKZSZf3jZC3g63NTyzL10hopZVVuMIXlrKzWd1wc1ndXF7Lj5Sz+qDAWQwSQ+SxvdMxV1jM3HX2EwIttm4CT1TsXRfIQDHMkM75rgQUUvjbx3yu1PljvKZeq0gNyhTPtm1b9cy54UoIMprWz54qU9BZR1+2HSC5ZJbWFFVHdYcLMLPW04AAO60BS2CYhnha/8YJG9zmRgRBRpnXsjvahTlTvVaDVY9NgGnyw2qaxKjpQ9My/YV4rp6SqgSnamOFldjxf5C3DAqo1le3x68JARJ8GJXWWdGbLgOn63JxeVDOiA+KrjGF8oqDSZkPfs35t0/Bt3SYgAAWc/+rbrGXilSKTZC+n/QMSkSV2Z1QHJMGIZ3SeKyXyIKCM68kN/VGh1/0GLCdWgXH4khndRP6+w5L4v25CPPKbAhIuCmTzZg5m+7UVVPn6Sm+L8fpFK4wTLzMucyqVxyRa0JM37bhdl/7MEri/YFeFSty/Sfd6LObMW5ry73eM2ozGSXY1qNgI9vysIPd42CIAiY2LsNYiP0SIlhvgsRtTzOvJDffbkuV96ODvf+LZZbXI22Hsq0Ep2pquqkJZVlNUbEuPk52nKsFAaTBaO7pjTpfeKCJHixNzdctr8QO0+UAwCSo/nh2J/+2HFa3t6fX4l9eZWq8+sfn4gwnftnmhN7t2nWsRER+YozL+RXOXkV+Gt3PgDgl3tH13vtF7cOB+Aoq0xEDlFh0uzke7au5iXVRmzKLZHPX/buGlz73/Ww1JMjUlVndlsCd6+tzC0AOSct0OwzQDN/3YV9+dKHal9ywa1WEV+uzUVhpftSv+TepNdW4F/fbpX3x/VIRZs4PkQiouDH4IX86su1R+Vtb7MusRHSebObNdZEZ7rjpTUAgK/XH8Phwipc8d4aXPH+WoiiiMOFVfJ1Ly90LK3KrzBgSU4+RFH6mbrgzZUuOQ2A1AwSAMKCqFJUYlSYvG3v/1Rh8L5k7ruNxzHzt90Y9pzr10lqiR7yhy4b0h5vXD3I7TkiomATPH+5qFUYZuucfcmgdHS3JYR6Yi+xaeTMC5GKKIoQFTH9Oa8sx+GiagBSbyTlLMOHKw7L2yOeX4xbP9uEC95aBQDILa5x+/pmq/Qz99M9o/w99EZLddMvRPm1uVNdZ8bjv+xsriGFvEvfXY3n5u0BIP23KlWUsVd66oK+SFAEj0REwYw5L+RXc23lNh+a1FNVatMde/DCmRcitVP1FLGoMVqw9nCxvO9u2djuUxU4XuIIXAoqDUiLdSwJyq+Qgp/M1PofMLQkT1XPRFGEIAh46rddOLt7Ks7tnYav1h3FRQPbY+DshaprLVYxaJbBBcJv207if9tP48qsDvho5WFsPVaGrcfK0L1NLDKSowEAEXqN3NMFAK4f2YkV3YgopHDmhZrs2w3HsHy/1MBs5YEiAIBO6/0DhN52TWvOecmvMNSbk0CktC+vEgcLKlFS5blZY43RLDeYVBJF9ffZmBeXyttP/robGdPm4bStB1NxVR0i9Bq3hQACReMh6LCX4/187VHc8cUm5ORVYuZvu10CF0AK0s5URVV1+Pd32/D33nzc9eVmbMwtlc89+tMObDkm7c+9ZzQWPjhWzjGa2IuJ+EQUWoLnLxeFnOMlNThYUIXpP0vLNjbNOFc+F6HTerpNZp95aa3BS0GlASOeX4wLB6bjrWsGB3o4FAImv74CANCzTSwAaSmVcyJ6rdGCz9bkyvvtEyIBABW1nvNDFuzOAwB8sPywfG+k3vvPaDDYebIcWYrGiDVG18a2XVOjcaiwGqfKatEuPrIlhxc03OU2Kc35MwcA0LttHDQaAW9fOxj/XXkE43qktsTwiIj8hjMv1GhjXlyKWz7bKO+vPeRYyuJLiWRH8NI6ZybsT8f/t/1UgEdCocZebeuXe0cjMyVade7jVUdU+yfLarHmYBHybbMOd43N9Pi6yqCn1uQaBATa8C5J8vY1wzsCkKqsVSsCFoObcV8/Ump0e/l7a5Fryw0iIM1NHpF9hmtM91R8cetwjzNeRETBisEL+c20uTsAADeN6uyxV4CSfWmZPXm4PusOF+Pp/+1u2gBbmE7xoYBLx8ibFball3YXDUxHh8QouSqf3XcbjwMApvZvKx+79qP1+H2bFCSf3b1pfV8CadaFfeXtMd2lGYEaoxlFitkn5+AlMUqPq7I6yvuvLNrfzKMMHY9O6YVPbs6S9901oCQiCjUMXqhRth4rdTlmfzoaGebbakS52pi5/uClsLIOV3+4Dp+uznVZ1x8oZTWecxLsXvv7gLy9/URZcw6HQtSX644iY9o8iKKIp35XB+c3jpJmE567tL/bey8f0kG1//bSgwCATklR+OluqYrYH/86299DblZ90uPk7XTbcrgao0XVq6ak2vGz9+LlA7D1yUmqmV4f0u1ajYJKA75adxQzfpWW7iZHqyuGZaZG45xebbD9qUn4899j8OVtwwMxTCIiv2LwQo1iX0MPOJrL2d00urNPrxGhl779ymvdl++0U/ZvMJis+GTVEdSZA7fkZf3hYgyavQjzd56u9zrlcrHL3l2DYjfNAunMVWe2YOavuwBIvVyOOC13snec79c+HrlzsnHo+amq852To7Bu+kSX102LjUBWRhJy52SjX/t4/HBX8JRDboiuqdJyuSd+2aX6HbHqoFQUZNnD43FlVgeX+8J9yLdrLYY/txgzft2Fr9YdAwC8cfVgVcDap50UDMZH6tG7XRx0QdTXh4iosfibjBpFgOPxZkZylOpcSozrOmt37B8y3lpy0OM1NUZ1EvKX63Ix+489+Fyxdr+l2WdR7v16C1bZqqu506ttrKopnKceC3RmsidQA8AMWxBjd/GgdHR1KmPsXAK4Q2IU2sZHYP79Y1THI8PUH97teSTXjeiE/1zeH0demIrlj4zHykcnNPlraE5RihncaT87ern8Zlse1zk5SlWOfc20cxAdpoUhgA82Ai05Jgz92sfjjasHYc20cxARIkUZiIgagtXGqFFEOJZvZabGYPuJcnlf74ene2U1Rizck49NuSWq45W2jtvPz89BZJgON4z0bZbHn5SB2zcbjnrMMdBqBAzplIjFOQXyPpFdfoX7sr47Z01CbIT3vhv2D6bKpVae5M7JVu13To72cGXg/f7Ps1BcbVT9vDhXXAPg0kcqPSESHRKj3Cb0t1bt4iNwWtETqG2c1Mvn4kHtAzUkIqJmx5kXapQ9pyrk7bvGZcqJoM9c3NfTLQ3yz2+24tGfduCHTSdUx5VlUmf+uisgOTDKz0zzd+a5nN+fX4nNR0tQa7QgIkyL+8/pBqBhSfvVdWbk1dOokEJffKRrR/PLBrevN3BZ8Uj9syXKJP5QNaBDAib0TGvUvafKa/HX7nxYFT9rxVV1qKpTz+D+vv0Uftl6wvn2kJMY5fgeGtcjVV5qSETUmjF4oUYZr/hw0attnDwTE+ehS7Y3VqcP9jtPlru9zrlM7HmvrcC9X28OeCJ/XrkBC215QNlvrsTl763FqfJapMaEy0/GG9LPZsavuzDyhcWoNHCpWWtVUWtCZmo0BnaIl4/9vPVkvfd0So7CO9cOwYIH1EvFljw0Dp/cnIV3rxvaLGMNNteP7OT2uH1mdt1hR9n2oc/+jXGKhp0GkwX3f7sVD36/vXkH2cyMZiv2nK6AViPg/H5t8e51QwI9JCKiFsHghRrFuaqNPXaI82G5i9Jlg6XlDZmPz8cHyw/Jx52T+D3N6BwsqML8nXlY7lRmtjmIooitx0pVy1XsK1vGvrQUd365GXtPV8h9awwmK9rERchlo30NXkRRxC+2D7HOM08U+k6X1yJj2jzM23kax0tqMPee0fL3yLTze3m9P3tAO/Rqq14qlpkag3POgE7p/7CVRLY38fTk2o/Wq/aLFRXKPl2d6/dxtSRRFHHR26vQY8afAKQZ3feuH+pTby0iotaAwQs1itk2U2KvbGOf9wjXN+xbalxPR3fn+j5U3DAqQ65O5k5LrHP/cfMJXPruGlU/DqsIPPLjdrnc8/lvrFTd0zU12qeS0CaLFRnT5iFj2jysUTT73HacJZZbm1EvLJG3TRYROq0Gyx4ej2tHdMJtZ3cJ4MiC37OX9sOLlw/AtSPc57p9fqvnUsCfrT6CaXN3uM2fCSVdps/HDkWO4ctXDgzgaIiIWp7XRzWCIHwC4AIABaIo9rMdSwLwPYAMALkArhJF0bXxB7VaFltjSXmNtS160QgNS0pXztTkeUhg3jLzPADA3eO64nVF7xSlCoPZ7XF/Ol0mjc95lufHzZ5nRzomRcmzSEaLFZe8sxpZnRNx4cB0XPzOaqydfg7axUdiqS2pHwCuUzw1/t/2U3jrmsH+/DIogCoUywAj9BosenAcACnZ/HkP/VzOZI9M7omiqjokRIZhSOcE6LUaXDWso8frx/VwPAypNJhwsKBK3p/1vz3NOtbmVl5jwrUfrXM5fsVQ13LRREStmS/zzJ8BeBvAF4pj0wAsFkVxjiAI02z7j/l/eBSs7DMv9i7y907oig2flqBX2/qXczhzN1PjXB45yRYg3TehG64Z3gnXfLgOh516YlR46RXjDwlRDc/n6ZoaI+fvXPtfKSjZdrwMH9lyd857dQV2PT1ZVTGIWq982//nFy7rj2uGu8/bIIf7JnRr9L39Zy3040gCQxRFnCitRcekKGw5XordikIpAHD/xO4BGhkRUeB4XeMjiuIKACVOhy8G8Llt+3MAl/h5XBTkymw9S+zBy/ieacidk42EqIZVuxnSKVG1b7GKyC2qcXutXqtBm7gILHl4vMs5ZRWyQIuy9dlIiQlDmE6DsHpKR9urIBVXG+E8aZWZGo24CJ2quziFFqtVVBWTMJikGctUH3shUcOd29v33J+Nuc5/2oLLk7/txpgXl+I/C3Lw0oJ98vFvbh+Bl68ciAcYvBDRGaixOS9tRFG0txfPA+Dxr4UgCHcKgrBJEIRNhYXNn1RNLWPPqQq0jYuQZ0Uay7mJ2jN/7MHUN6W8kXeuHeLSn8JuRnZvROg1eOfaIdBqBBhMFny17igyps3D1+uPNmlM7lQYTHjq992qY57yE6bbkq7TEyIBeO/vklduwO6T5UiI1GPfs1Nwqa2IQeekKFQYzMh69m98tPJwU78ECoDMx+ejy/T58n6drYFiQ3PDyHdxEb4nrp8odf+gJFh8uU76XfbeskPYc9ox6zIiMxlXDO0ADXtHEdEZqMl/QUXpsaLHOrWiKH4oimKWKIpZqampni6jEFNtNCMtLtylUVxT/bHjlLxdX6/L28dkIueZ85E9oB0sVhE/bj4hl1Ge5RRk+MNV7691OTa5b1usnnaOy/He7eIQG6GTK0cpg5ftT05yuX7kC4uxOKcApTUmhOu0eOXKgdjwxEQM7eyYlVq4J98fXwa1oDpFp/e+Ty7A8ZIaVNtmCMN17HzeXBpSdevB77fjtUX7m3E0/nXhwHTkzslmw1siOqM1NnjJFwShHQDY/l3g5XpqZWqMFkTq/fMB7Jd7RyPL9kFducSqIcn/hZV1ctllk0XEvrxKv4xtf34lMqbNQ46b1+uWFoNYN095k2PCsXPWZIzumgLAUU5ZpxEQH6XHtifPc/te9i9XoxGQFhuBZMXSosOF1W7voeB12btr5O1qowVjXlyKmz7ZAAD1Vs6jprEv21QamZmk2h/TPUXefmOx+yIggVJQacCg2Qux5lCRy7loN18bEdGZprF/QX8HcJNt+yYAv/lnOBSsRFHEx6uOyMssaoxmv/UVGNwpEef3bwcAOKVIXG9o5bIyRdL+5NdX+GVs36w/5vb4hscnIik6DLFu/hvonJ6K2men7EvslHlB0xV9PZY+NF51n7KXDvNeQsvmoyUuydVKDf3eJt+5Wwbg3H+qQ2JUywymEZbvK0RZjUku8KGkr286mojoDOH1N6EgCN8CWAugpyAIJwRBuA3AHADnCYJwAMC5tn1qxU6U1uKZP/bg399tAwDU1FkQ6cengOE6129FTQP/TivLovrrs6GyuZ1d7pxspMVF2N5HQP/28arzYU5fi32Jh7sPHneN64qlD4/HH/86Gxkp0apzyUzqDlkFFfUHm3X19PyhpkmPj1Dtr5s+0WWZlbvfN8plfoFSXmvCIz/t8Hh+eJckj+eIiM4UXh+di6J4jYdTE/08Fgpim45KVXk2Hy1Fjxl/wmi2qhpMNpW75VcNfTqt7L8iisCB/Ep099KJuz4/bDyO/20/5f26u0ah0mDC8OcXy++tZLUdcA5q7Lo4BS12KTFNK4ZAgaMsRLFn9mQIEND3qQWwVRhH73aN/76k+t04KgOFVXV4Z+khPDK5J9rGR7g8zHD+mXt32UG8uGAf5lzWH1cHsIS1u8Ic/3deD9w0KgPltSZ0Sg7eGSMiopbin3U/1Oo9+P12edveKX58zzS/vX73NNcPcx6rQPjovNdW4PDzU/HA99tw9bCOGNU12ecCA/vzK/HoXNcnoHMuc20kGBmmVc1CxUWqf6zMFnVPHAB4+9rBSItVPyF2ppx5cV6KRsGlwmDCjuPluPXzjfLPBwAseWgcosKk74c//z0Wk19fgZtHZ8jHyP80GgGPTO6F8/u1Q9/0OABw+bnv6dSP6kVbGeJpP+9Ex6QonNUtBS2toNIgP4C5Z3xXfLEmF2umT0RchA6CIOXLERGRH6qNUetjtarDBovVNYwYlZmMMX78A58W57pEqrjKdcmWO3/+e4y8/eVtw9FG8VrL9xfi9+2ncO1H69Fl+nyfl4Y89MN2l2PXDO/o01NZ5w+mJov0YVa5bOyCAelel4BEh2nxzwndcE6vNJitIl5ZuA8Z0+bhYIF/ihGQ/wx79m9c//F6VeACOMplA9IH5g2PT8TjU3u39PDOSP3ax8tBi/Msbnyk50Dguo9cc01awvDnFmPHCamh7WNTemH37CmIj9T7vaIjEVGoY/BCKn/uPI3Mx+fjK1t/gQP5lej6+HzVNUdemIpv7xzp1x4DKW7yO5yDKE96t4uTt8d0T1Utz7rls42qa3vOWACDyXsAU+Im18W5J42v7IUN+rWP83KlmiAIeHhyTwzplAAAeGvJQQDAua+ugMUq4p2lB1FQaajvJaiFeMphcf6eSYuL8Lh8kJpPj7QY1X5arO/5ZCv2FyJj2jzsqacAg7O5m0/gh43H3Z4TndeVEhFRg/CvKKn8svUkAGDGr7sAABe9vdrlmuZ8EqhMrL1sSHuf77v/nG64ZnhHAMAEL8vZ/vXt07BycwAAIABJREFUVgBSd/vjJe6b1JXWuAYvyoIADdElJRrf3TkSsy/u16j7d54sdzmWk1eBl/7ah+HPLcbna3Ib9brkP8oA2m5yX987vVPzundCN3x/50h5PzHK93yyG23lre3Nc70xmCx46MftbpedLtydh/6zFqKwktUDiYgai8ELqSibIe46WY6sjMR6rvavH+8ehRWPTsDKRydg7fRzoGtAWdD/m9QTL1w2AAAQ46WEc0GFNFtx48frMebFpW6vUX64sZcsLqsxub3WFyMzkxs9c6PsrG234UiJvP1UMzTlpIazz5ABwKQ+bTDzgj4BHA0paTUCRmQmy/sajYDHpvTyeH3GtHn4ecsJ1bFebX0rsrD7lONhg720PABszC3BnV9uRlWdGafKalX31BotEATggXO7I3dOtk/vQ0R0pmLwQrKNuSWq/U9X52LlAalR2qHnpzb7+w/LSEL7hEh0TIpCu/hI7zd4MKVfWwDAhJ6pOL9fW3RNjcaupycjd042UmPD5QpkW46VAYDbZWT2fJQtM8/De9cPBQC/LpNriHZxrv8tnv7fHnk7XKdBbhGbWAZSdZ0ZnZKikDsnG7lzsvHhjVlB3UvkTPXXA2Px1W0jAEhJ8Ude8Px77eNVR+RZWgAY2tn7g5zFe/PxwPfb5P2z/+N4OHLl+2vl7RqjBa8u2o9DhdJs7qHCKogi0KMJ1RGJiM4ULHlDAKQKYso/rnEROsxVPHl07pMQzAZ0SPD49DIxSo8qg1l1rLjaiPYJ6gCh0mBGr7axSIoOQ3qCVBVsYi/v1dXG9vBf+Wi7F68YgPEvL/N4vs5sxfiXl2HJQ+OQmRrj8Tryv5y8CtQaLThWUoOzu7d8hSpqmJ5tY1WVxgRBwLUjOuGb9cfQPiESJxUzIrtPVagajXpLwVt/uBi3fb7J5fhTv+3C52uPqo69tmg/NuSW4M3FB/DpzcPk5brd0/jzS0TkDYMXAqBemvTiFQNwtLga7yw9BAB4+cqBAICFD47FydJat/eHiphwHcpr1cu/iqvqXIKX6jqz3HumQ2IU1j8+EalemkYeen4qmiPES1EkF+u1AkwWx6eof2R1xPebpMTgbcfLGLy0oJ82n8DDPzqq0jEROzTZ895OltXi5tEZ+MxDDpm3AiLOv1fslIFLVJgWNUYLNihmuZVFRfjzS0TkHZeNEQCprwkgVeG5Kqsj7hnfDX3T4zDrwj64YmgHANKShgk+zD4EM6sIrD1cjFmKPJFZbnJGqurMcpUwAGgTF+F12ZhWIzTL0rJIRa7Mq1cNkrdvHp2hau7JpWMta4WiKSogNXCl0GNVBJ2zLuqLnGemuFyj1Qiq6xbsysMNH69XLTktcwpe9sye7PI6ylmf+yZ0VZ17bEqvkJrhJiIKFM68ED5Yfggv/JkDAFg7fSIAaYZi3v1j6rstJGV1TsS242Wqp6v23Bel4qo6dA6SbtZajYCtM89DQWUderaNxYUD0yGKIgRBwBt/H5CvW3+kpJ5XIX9zzpX64tYRARoJNcXsi/vh6g/X4X//PBuAVN56XI9UuWHkpD5tsPtUBSyK4OXurzYDAL5cexR3jM0EIM18AsDVwzoiNkKHqDAd4iP1qhmZ60d0xlbb75t/T+wBo9mK/648AkDKwSEiIu8483KGcNdoEpCq4dgDFyC0clsaw5eclLxyA06VG1wKGARSYnSYy1p9AIjQO36Ec/LYvLIl2ZuPAtL/h7bxEQEcDTVW19QYbHziXNX/v+WKWbWFe/Kh1Qiwxy5lijLqz83fC0BaMpZzugJ90+Mw5/IBeCJbqjRnLw7w/KX9sWXmebjcNosNAGE6jXwdERH5jjMvZ4Dftp3Ev7/bhmUPj0dGSrR8vLCyTlUN531bVa3WrEOi+ypm13+0Hm9dMxiJ0WHyU9ULBqS35NAaRdkcsbzWhBqjGVFh/LFubgt25WHpPscHXKa7tC4jM5Ow7rDj4YVGcDwAWqQoJ3/ZkPbYdbIcF7y1yu3r9O8Q71I8ZPr5vZAQpZf3d86ahHBd48qoExGdiTjzEuJMFiuW5hQgt6ha9UQQkBKI31x8AP/+Tird+b/tp1Tn7/jCURnnl3tHyyWGW7PM1BjMyO6NmRf0Qe6cbNw/sTsAYNXBIgx+ZhEqDCZ5+cetZ3cJ5FAbxN6LpqLW7OVK8ofl+wsCPQRqRneNdSzhCtdpkBwTjt+3n8Ibfx/AIz85mk/+vOWkx8DF42uP64p/DOsk78dG6BGm459iIiJf8TdmiJvy+grc8tlGjH95GQbNXqQ6t2xfIV5dtF/ef2XRfvR9coG8b/+QPuvCPhjcqeWaUQba7WMycZstMJnUR90FfcCshRjTPQWdk6NcKpAFo/hI6Qluqq0imbueNeRfRrMV3244rjpWX8NDCj0TeqXJOTDf3TlS7sfy2t/767uNiIhaANeXhLhDheoKU7VGC3RaATqN4Lb6UbXRglqjBZFhWkTqtchMjcbNZ4XODIO/9Wsf73Js5YEiDOyY4Obq4HPtiE4wWaxIiQnHA99vUy0jo+axJMcx6zKpTxt8eGNWAEdDzUW55CvczczIM5f0w8xfd6mOfXfnyBYZGxHRmYwzLyHOuSLWE7/uRPcn/kSX6fPx9tKDqjK7dnd8sQk/bT6BWpOFa/Xh/qn59uOuFciCkV6rwe1jMhFjK+vMmZfmd6K0Rt5+ydYDiVq3q7I6qvb3zp6CG0Z2xq6nHeWQc56ZgpGZyS09NCKiMw6DlxCXECXlOvxw1ygA0hpspVqTBT/fOxo7Zk2S+wqsOlgkN9d7ZErPFhxtcLpnfFccen4qNj5xbqCH0mgRtiCVMy/Nr9LgyCuyL9uj1u2Bc3vg6mFSAHPl0A6IDJN+3mLCddj+5CTsnT1F/hkkIqLmxeAlxJ0srcUlg9IxLEOds9I5OQodkyLxxtWDMKRTIuIi9Eh3k8MxpltKSw01qGk1AlJjw7HvWalBXWx4aK2oDLeVTP52w7EAj6T1e2Ox1FvnjjFn7nLLM41WI+BOWz+X28dkqs7FR+nlYIaIiJpfaH1CO8Ptz69Ep6QoROi1KK02otpoRlFVHTomRcl9PwBgxSMT0MlNg8VrhnVCekIkbvl0IwDg01uGQadl/KoUrtPi81uHIyNIGlT6KsJWavWXrScx5/L+LL3aTJS9Xdij48ySmRrjUvaYiIhaHoOXEFBea8LT/9stLwlb8MAYTHl9pXy+d7s4AMB1IzohJSbcbeACABqNgAk903DXuEx8sPwwEm1LzkhtnA+NLINNuKJZZXmtCWmxDF4qDCbM/HUXHp/aG23i/NNA8vbPpfLit4dQGW0iIqLWhMFLCHjj7wOqXBZl4AIA/W0Vs567tL9Pr/fAxB4Y0SUJAzu4Vtqi0KSshnTzJxvxv3+dDa1GqOeO1u+3rSfx27ZT+HNnHowWK8J0GuyaNbnRPTVyi6rlzuvnOpXYJiIiopbB4KUFnSitwbcbjuHhST1Vy7wAoLiqDttPlCFcp8XQzonQaQTM/mMPvlh71Ovr/n97dx4YVX3uf/z9BBJICIYdQSiLbIIIyiIqgqK41Lpv1Qtc8Va9btUWt6vWpS7V+qtrrago3ttatde9YsX1KoqAoCCKC7IKRgw7BEhI8vz+OCdDVsgyzOQwn9c/mXPOLN/hYWbOc77f7/Pt3Kp2Q5wyMxoxqo9OvvYkZcfcL8jdyIp1W+jSulkSW7T7bNi6nZISp2WznfcclhbSKwyHehUWlTB/5XoGdWlVq9eb8nkul/7903L7+ldRYltERER2PyUvCTT87vcA6NmuOScc0IH0cL7J9EWrOffxmTt97EkDOvLb0b3o2qYZb3yRS6eWWWQ3aczmAq2oLtAis/yJfNmKWBXlbthK86bpsfLKUTPg1jeBoMLe0G5VJyKL8jbz+YoNlfYv+GFjrZOXiokLQLOI/tuJiIhEnX6BE+Cnjdt448sfY9tXPjeXK5+by4fXHkmnlll88O3qah972ZE9aJGVzvmHdSMtHAZ03P4ddnubJVoyGqex9K4T6HrdFADW5BdWus/ivM2M+tP7se3XLh9e5SKdDVV+QRFPTV8a2z7r0Y+Zdf1RtKswn+Wz5es49S/Tq3yO373yJZgxdliXGr1m3qaCOrdXRERE4k+lpnYzd2fone9w0ytfVjo2/O736HrdFCa+vwiA+bccw9K7TuCDq48E4I5T9+eqY3vzq8O7xxIXkZ0pXeF7XRXJy52vf11u+7zJsxLSpnh5avpS7pn6Tbl9Q+98h2Vr8mPb24tLuOzvn8W2u7dtRrc25YfP/e7lLygqUzUsb1MBBUWVF/csKi5hyB1vA3DKwI58fssxABxcTW+PiIiI7H7qeQH+39RvmL1sLc9eeEhcnm/D1u00y2hE7oZtHP7H92L7J48fQpNGaZw7qfIQsZZZ6TRvGix497PWWSrJKXXSZ+/mAHywMI9D921drleiwjQrVm8uZF1+4S7njjQUMxavid1++dLDOOXhjwC4/JnPyExvxMwla2PHB3VpydO/OhiAJz5cwj1Tv6FL6yyWrdkCwJT5uZw8cB/cnSF3vM2x/drz6NjB5V7vvre/jd2+9vg+7NU0nfevPoJ2zeNTuUxERERqL6WTl7X5hRx97/usDa9Sz166lhKHaQvzGDusC9+s2sThPasvm7t6cwGPfbCY/xy5L63CE8D8gqLYmPyyPv6vUXTIycTdeeHiQ5j4/mK+yt3I0G6tmPv9el66+LDd8yYlpezVNB0zePHTlcxaspYPrx0FQEmJ89aCVZXuf/oj03lnwshKBSQamvVbCunUMlhkdUSvtgzs3ILDe7Zh2sLVVc5tmTC6V2zF84tH7stJAzrSqlkG/W6eCsAVz87l5IH7xOaMTf2y8r/NG1/sGOrZISd47T21CIKIiEhUpHTycufrX8USF4AzJn4cu/3Qu98BcNdp/ckvLOa21xbwwdVH0iQ9jTe++JGvf9zIM7O+B4IqRuMP68ox931AQVEJFY3o1TZ28mNmDOrSisfHaeiJxF9amuFhma0V67bG9q/atC12+4af78c3qzbx/JwVLF6dz4zFazlk39aJbmqNlJQ40xetYcwTO3orH/rlgQDce9bA2LCusiaOOYhDe7SJbaelWawi30kDOvLqvB8A6HnD67x62fByr1U6PHNzQRGL8oLhaOMP6xrfNyUiIiJ1lpLJy6wla7l9yoIqr9hWdN2L82O3R9zzXpX3eWr60nITicvKTG/Ew+ceWKd2itRX7oatdMjJZO7y9bF9F4zoztMzl/H8nBUAnPP4DCaPH0KHnKb02XuvZDW1ktfn53LJ05UrfeVkBcMr2zZvUunYroZbPvDLgbHkZXuxc/wDO9ZM6n7968y58WhaZzdhWrieS8922dz0i751fg8iIiISXymZvLh7ucTl29uPZ21+Ia2aZfDQuwtjvS47k5OZTpPGaRzQKYe3v/qp3LF/P6QL+7bL5rSDOkW2HK3sGV76bCWXHNGDrduDCelv/3YEsGNuTKnxkz8Bdn3yn0hVJS7/uKj6eWk1WfXezLh8VI9qP+NnTvyYW07qR/ucYF7LhGN6NfghdSIiIqkkJc+sD+rSMna7V/tsMhqnsXfsZKU3x/bbmzMnfsy/rjicrmGlosKiEpav3cKWwiJ6tW8eG0/v7jw9czn7dWjO7KXr+MO/vubMwZ0jVYJW9iznH9aNJz9aAhDrcdkeVtfKygg+8oO6tOKTG45mzKSZfLNqU3IaWgcVK4ddPqoH3/y4iYljBtW4It8VR/VkUJeWnBcmbGUtXp3PuCdn8fuT+wGQ3SS9/o0WERGRuEnJ5KV0cUiAh845qNLx/ffJ4avbjiu3L6NxGj3aZVe6r5kxJlwzYlCXVlw0ct84t1akdm46sS83ndiXMZNmkrc5WKekMJyLVfb/ftvmTXjuomHc//bCaoc9JktxicduP3TOgYzq044fN26rNFRswjG9a/3cjRulcUTvdgzp2pJPlq7jiqN6cumRPRj35ExmLA4qlpWWNm+SrmryIiIiDUlKJi8A704Yyevzc+nVvnJCIrInaJOdwdJlwaTzwuIgGchoVP5kvEVWBrec1I8FuRv5bPm6hLexOn+bsSx2+8QBHQHYt218P6vPXXgIJe40Dv9NLj2yBzMWl1/7Jt6vKSIiIvVTr+TFzJYCm4BioMjdB+/8EQ1H97bZXDaqZ7KbIbLbZGY05qeNQc9L7vqg8lhG46p7EtpmN2F7sbNp2/bYekPJ8srclfw1TF4mjqncMxovaWlGGjuGmh3cLai4tlfTxmzcFpRQbhWRNXBERERSRTx6Xo5099VxeB4RiaO3v1pFYXEJMxevYdKHwRyY9EZVzwuZMj8XgP63vMmSP/ycHzZsY58WmQlra6k5y9ZyxbNzAejaOovj9u+QsNfOaJzGF7ceS2Z6I5aszicnU/NdREREGhoN6BbZQ+VtCnpdzn5sBgAdcprGhkhVdO1xfWK3J3+0lMPuepeFSZjI/895ubHbS9dsSfjrZzdpTKM0o0e77CpLMYuIiEhy1Td5ceBNM5tjZhfGo0EiEh8jerUtt112QdaKyi7E+PvXFgCwbDckDyUlzntf/4S7V3m8b4dgnZle7bO5/+yBcX99ERERibb6Ji/D3f0g4HjgUjMbUfEOZnahmc02s9l5eXn1fDkRqam7T+9fbvvGnSy2WFr6u6y1W6pPdupqyvxcxj/1Cfe99W2Vx/849WsAnrlgGKccuE/cX19ERESirV7Ji7uvDP/+BLwEDK3iPo+5+2B3H9y2bduKh0VkN+mQs2POyl/+7SDGhiW9q/PHMw4ot73op81xb9OmcCL8g1UsEllYVMLqzUHC1DJLE+VFRESksjonL2bWzMyal94GjgG+iFfDRCR+2tVg/sax/fYut/3oB4uZtjCPDVu3x60d368LhqJ1r7DYJBAr1fzY2JovOCkiIiKppT49L+2BD81sHjALmOLub8SnWSISDz3DhVUHd221y/vmZKYzvEebcvvGPjGLG16aX682LF2dz8eL1rBtezGP/N+i4LWy0vmvFz+n63VT2FIY9Mb8+b2gN2a/cN6LiIiISEVW3cTZ3WHw4ME+e/bshL2eSKpbv6WQleu30q9jTo3u7+5sLihixbqtHP/ANCBY6+TT342ucxu6Xjdlp8c7t8rk+7VbY9tL/vBzzNTzIiIikqrMbE5160eqVLLIHqxFVkaNExcAM6N50/RYjw1AfkFRXNvUq335VevLJi6j+7ZX4iIiIiLVUvIiIpWUXQ+moKgkbs8758ajefM3I6tdAPKoPu3i9loiIiKy51HyIiK7tG17ca0fs6WwKDZkrG+HvVh61wm0zg4KB7Tfq+oCAiqPLCIiIjuj5EVEdun+txfW+jEzFq+J3V6Qu7HcsTMHdQYgK2PH+jJL7zqhyvVmREREREopeRGRKr1w8aGxtWEmvr+ImYvX8Jvn5lJcUrMiH+c/taM4R8UKYheM6M68m47hnQkj49dgERER2eM1TnYDRKRhGtSlJQM65fDXGcsAOPuxGQBcfWxvOrbI3NlDy2mansbNJ/attD8nK50c0nlnwkg6t8yKT6NFRERkj6bkRUSqVXbifqnNNaw+tk+LTPrvk8PEsYN2er9922bv9LiIiIhIKQ0bE5GdGlWhAtiqjdtq9Lj8wiLaVTMxX0RERKQulLyIyE49ed4Qrj2uT2x77BOz2NXitu7Oxq3b2atp1SWRRUREROpCyYuI7NJFI7qX2964dedDx7YUFlPikN1UI1NFREQkfpS8iMgupaUZd57anzHDfgbAqk2Vh44tW5NP7xv/xZxlaykMF7Zs2lhfMSIiIhI/uiwqIjVy7sE/46PvVvO3Gcv56LvVfJW7kZMH7lhUct6KDRQUlXD6Ix/H9hUWlySjqSIiIrKHUvIiIjXWJOxJufWfCwD4xQEdaZRmAPzmubmV7r987ZbENU5ERET2eBrTISI1ZlZ+e/naLZSUOF2vm1Ll4pXDe7RNUMtEREQkFSh5EZEaG9CpRbnt1+b9wI9lSifnZO6oLjbvpmM4bv+9E9Y2ERER2fMpeRGRGqu4aOX/fZvH0tX5O7avOiJ2OydLZZJFREQkvjTnRURq5e7T+9MiK4OH3l1ITmY6d7z+FQDTrjmSls0yeHzcYJqrRLKIiIjsBjrDEJFaOXtIUC550rTFbNtezJc/bASgU8tMAEb3bZ+0tomIiMieTcPGRKROmqY3YtXGbZjBBYd3wyrO5hcRERGJM/W8iEid5G0qYFFeMN+lXfOmSW6NiIiIpAL1vIhInazbUhi73bJZRhJbIiIiIqlCyYuI1Mn24h3rupw0oGMSWyIiIiKpQsmLiNRJfkEREFQZy2isrxIRERHZ/XTGISJ1UlBUAkDrbA0ZExERkcRQ8iIidXLNcb0ByMpQ3Q8RERFJDJ11iEidXHJEDy45okeymyEiIiIpRD0vIiIiIiISCUpeREREREQkEpS8iIiIiIhIJCh5ERERERGRSFDyIiIiIiIikaDkRUREREREIkHJi4iIiIiIRIKSFxERERERiQQlLyIiIiIiEgnm7ol7MbM8YFnCXrDhaAOsTnYjpM4Uv+hS7KJN8YsuxS66FLto21Pi18Xd21Z1IKHJS6oys9nuPjjZ7ZC6UfyiS7GLNsUvuhS76FLsoi0V4qdhYyIiIiIiEglKXkREREREJBKUvCTGY8lugNSL4hddil20KX7RpdhFl2IXbXt8/DTnRUREREREIkE9LyIiIiIiEglKXkREREREJBKUvIiUYWaW7DZI7ZhZVvhXsYsgM0tPdhtERCQ6lLzEiZk1TnYbpPbMbLiZPWJmlwC4JoFFgpmlmVkrM3sTuBoUu6gxs2Fm9ixwj5ntn+z2SO3pgkF0mVk/M2ua7HZI3ZhZo/BvSn4GlbzUk5kdYmaPA0OS3RapHTM7CHgEmAP83MzuM7OBSW6W1IC7lwBFQA7Q3cyOhtT9Io8aMzuT4LP3GtAU+G24X/GLADMbGv7uXWtmVa6ALQ2TmR1gZh8CtwOtk90eqR0zO8zM/hu40cxapepFOyUv9WBmFxCUpPsU+Kw0E5bIGAp84u6TgF8BWwiSmDbJbZbUUF9gFTANONHMMlP1izyCegL/dPe/AfdBMHxM8WvYzKyRmf2B4HfvI+Ag4GYza5/clkkt3Ag87+6nuvtK0EWDqDCz7sBfgPeALsBtZnZCcluVHEpe6udnwA3u/oi7b3P34mQ3SKpnZmeZ2W/N7NBw16dAtpnt7e4/Au8CbYHhSWukVKlM7IaV2b0M+AL4FigBjjOzvZPSQNmpMvE7JNz1DXCamV0DfAx0BB42s8FJa6TURBqwHDjL3Z8CrgSGAZnJbJTsWjjUtjuw2d3vD/eNNrMWQEoPQYqQIcBX4WdvAjAX+IWZdU5qq5JAyUstmFk3M2sS3m4F7A/MMrNRZjbVzK43s9PC4/oSaCDCq4U3AdeGux41sxOBfGApMDLc/z6wHugUPk4xTLIqYvd46WcMGAhkufsHBHF7CLjdzBordg1DNfE7CXgRuAIYAYxz9+OAPOAMJaANSzg3qVe4WQI84+7fmlkTd/8BWAGot7oBKhu7cKjtauBwMzvBzF4GrgIeRPMGGyQzO9HMLitz0e4ToLOZdXb3dQS9n+uB06p9kj2UkpcaMLOuZvYvYBLwdzPbz93XAmuAp4FTgIeBXOAmMxugL4GGI+wR6w1McPd7gVuBy4DGwA/AQDPr6+5FBFeETw0fpxgmWRWxuxn4dfiD/AOQb2aTgfEEPTCfu3uRYtcwVBO/3wC93P0dYBvBZw7gFeAAgosKkmRm1sLMpgBvAWeZWba7F7v7egB3LzCz5kA3gs+iNBBVxK4ZgLtvBCYDtwFPuvuxBOc1wyr0aksSmVkHM/sncA3QEphsZse6+2KCnuqzwrt+AywAWqVa8QUlL9WocOX2KmCmux9FMLTodjPrRvBD3B/IdfdX3X0y8DpwcsIbLOWY2TgzGxl2iUMwN6KlmTV29+eBRcBognhuI5i8CLAP8ImpelzS7CJ2LwJfElwwaAscC2wEBgD3AAeaWdfEt1pK7SJ+LxDE75ywh2URcEZ4vwMJPovSMDQDpgKXh7cPr+I+BwNfuvsPZpZtZj0T2UCpVsXYjShz7DWgK8FJMcBsgs9oQQLbJzs3GJjm7oe7+23AA8AF4bFpQH8zGxpeHFoJHObuKfXdqeSlek2hXAnkBQDu/jAwCLiIoAt2EnB6mce1A6YnrplSygIdzOw94N+BfyMYR59NEKv+QHZ49weBMcAqd78VWB9eqfolMCnshZEEqWXs/gycA8wDRrn7Fe6+gWD87zXuvjThbyDF1SF+pwDFwJvAEDObAZwJXO/umxL+BgQol3juFU7mfgz4B0FSebCZdQzvV/q72AL43szGEwxpUbXGJKlB7PYBcPfPCYaJXWZBcZoxBEPg1ySp6UIsfkeEUxPeAf5a5vAaYGF4eybwGXBf+P3aD1hu4XpnqULJSwXhBLa3CNYeOCs8iV1LcEV3gJkNIJgk3Bno7O7XE/zHuSv8AW5FcGVREsjMGoVDhZoDK8NesosJrso/SFCh41DgADPLcvevCYYZnRs+xUXAee4+xN2/S/w7SF11iN1XBF/k57r7Rgsmoqa5e6675yXrfaSqOn72FgJnhkPHxgEXuPvR4TFJoGoSz0fMrE1YiGYL8DbBlfpRAGUu7pxMcCI8Ajjb3f838e8gddUldgDu/gTwDHALwcXXX7n78oS/gRRXRfzOBZ4kmMuZazsW8O1A2FPm7j+6+wMEScyTBMnn3WGsU4aGxpRhZj0Ihg/dSVBR5ZrwysQ9BFVV7iC40nQlwboEJxKU+TyPoFrOu+7+ZuJbnrosKE99G9DIzF4H9iK4oou7F5vZZQRzkf4E/J2gZ6UD8BywnbCXzN23E0wYlgSJQ+xmhPctSXzrpZ7xKyRYXwl33wwbkb4fAAAFuklEQVTMT/gbkNLEszicu7LS3ceEcb2f4Mr9aQDu/pGZDQX6mNleQEkYtynAK+FQXEmgOsSut5nlEMRuk7vfa0F58u3Jexepq4bxK/1tG00wdAwza+fuPxHMh8lM1Z7qlO95Kb1qG24eDMxx91fc/TOCKxZ3Ak3DcYe/dvfh7j6boMpD6X+aTe7+tRKXxDKzkQQnQC2B7whOpLYDR4Zf1qUThm8F7nH3/yEYpjLOzD4jSN510pQEil20KX7RZkEVuDuBO8NY9qZM4klQCe7Q8FipxwmG/r0DLDKzDu7+rBKXxKpn7N4Cvisd/qfEJfFqE78wuckguLD6rZndAbxlZi3DwjQpmbhAiicv4TjdFQQ/vBD8mP7Sgsn4EPzALiJcRA1YEj7uQuA/CNYJUVWq5CkB/uTuF7v74wTD+boBNxGs3k2YmL4AbLGgvODLBLE73d3PTrWu1gZEsYs2xS+iaph4lhAMKbqlzENPAC4hmFvW391zE9dqgbjEbh5B7FQdLglqGb9bw4c1JRjd8w7B0NyjPSiTnNJSNnkJJzqdDNwNHG9mfcKJbP9DkBF/RFBd5TyCSjnt3d3N7EqCqg8XufunSWq+BOYA/wi7WiHoDfuZBws4NTKzy8Mvgk7Adnf/HmJjRhcnpcVSSrGLNsUvumqaeL4M5NmO6n3bCE6cLgiHrUjiKXbRVpv4/WRmnYA+wN8I5gj+WvM6AymbvITjdX8dTnx6kx1Z7gTgUuBadx9DsABQXvgX4DEPJnV/kug2S3nuvsXdC8KuVgjGhZZ+sMcD+5nZawQTE5VoNiCKXbQpfpFWm8Sz2MPqfeFw6g+S0WCJUeyirTbxK3H3Fe4+y93HufvcJLW5QUrpCfu+o7rG/cCrFiwCNNXMNrj7h+Gx/wS2AEXhYzTUoYEJvwgcaA+8Gu7eBFxPUAJyiQelI6WBUeyiTfGLnip+w0YDn4e3xwMXhIlnb4KJw5iZaXh08il20ab4xU9KJy+l3P1HM3uC4Ad3ajhJaihwA5AOnF/mCqM0PCVABsF6EgeY2f0EddEvL5OESsOk2EWb4hdRtUk8dfLUsCh20ab41Z/p3yUYY+juJWb2PEFpzwKCSmML3X1RclsnNWFmwwjKHk8HJntQx14iQLGLNsUvmszMCBLPScBLwPnsSDw3JrNtsnOKXbQpfvWn5CVkweqkbwB9gd+7+4NJbpLUQjixbSxwr7sXJLs9UnOKXbQpftGlxDO6FLtoU/zqR8lLyMyuIpgkda1+gEVEZE+nxDO6FLtoU/zqR8lLqHToWLLbISIiIiIiVVPyIiIiIiIikZCy67yIiIiIiEi0KHkREREREZFIUPIiIiIiIiKRoORFRETizsyKzWyumX1pZvPMbIKZ7fQ3x8y6mtm5iWqjiIhEj5IXERHZHba6+0B37weMBo4Hbt7FY7oCSl5ERKRaqjYmIiJxZ2ab3T27zHZ34BOgDdAF+CvQLDx8mbtPN7MZwH7AEuC/gQeBu4AjgCbAw+7+aMLehIiINDhKXkREJO4qJi/hvvVAb2ATUOLu28ysJ/CMuw82syOAq9z9F+H9LwTaufvtZtYE+Ag4092XJPTNiIhIg9E42Q0QEZGUkw782cwGAsVAr2rudwxwgJmdEW7nAD0JemZERCQFKXkREZHdLhw2Vgz8RDD3ZRUwgGDu5bbqHgZc7u5TE9JIERFp8DRhX0REdiszawtMBP7swVjlHCDX3UuAsUCj8K6bgOZlHjoVuNjM0sPn6WVmzRARkZSlnhcREdkdMs1sLsEQsSKCCfr3hsf+ArxgZuOAN4D8cP/nQLGZzQOeAh4gqED2qZkZkAeckqg3ICIiDY8m7IuIiIiISCRo2JiIiIiIiESCkhcREREREYkEJS8iIiIiIhIJSl5ERERERCQSlLyIiIiIiEgkKHkREREREZFIUPIiIiIiIiKRoORFREREREQi4f8DwN1vtWPba+gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j37ktQLT1B9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "close # dont worry, be can stick it back in the DF to get back time... for plotting purposes\n",
        "#do_stuff_to_close()\n",
        "df['close_V2'] = close "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGYoiexZ1gM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "eaa799ad-70bb-4487-bcc3-8afd20bc4b3f"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>close_V2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995-01-12</th>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.8450</td>\n",
              "      <td>5.9075</td>\n",
              "      <td>2.139365</td>\n",
              "      <td>394400</td>\n",
              "      <td>5.9075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-13</th>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.9375</td>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.8125</td>\n",
              "      <td>2.104961</td>\n",
              "      <td>76000</td>\n",
              "      <td>5.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-01-16</th>\n",
              "      <td>5.8125</td>\n",
              "      <td>5.8450</td>\n",
              "      <td>5.7825</td>\n",
              "      <td>5.8125</td>\n",
              "      <td>2.104961</td>\n",
              "      <td>70400</td>\n",
              "      <td>5.8125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close  Adj Close  Volume  close_V2\n",
              "Date                                                                   \n",
              "1995-01-12  5.9375  5.9375  5.8450  5.9075   2.139365  394400    5.9075\n",
              "1995-01-13  5.9375  5.9375  5.7825  5.8125   2.104961   76000    5.8125\n",
              "1995-01-16  5.8125  5.8450  5.7825  5.8125   2.104961   70400    5.8125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyuTDZ9cwz7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "25b112a2-9841-4c74-ca9f-f3a46a041cfa"
      },
      "source": [
        "df.tail(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>close_V2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-07-14</th>\n",
              "      <td>22.690001</td>\n",
              "      <td>23.200001</td>\n",
              "      <td>22.690001</td>\n",
              "      <td>23.160000</td>\n",
              "      <td>23.160000</td>\n",
              "      <td>2228500</td>\n",
              "      <td>23.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-15</th>\n",
              "      <td>23.230000</td>\n",
              "      <td>23.570000</td>\n",
              "      <td>23.230000</td>\n",
              "      <td>23.549999</td>\n",
              "      <td>23.549999</td>\n",
              "      <td>2162300</td>\n",
              "      <td>23.549999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-16</th>\n",
              "      <td>23.410000</td>\n",
              "      <td>23.920000</td>\n",
              "      <td>23.410000</td>\n",
              "      <td>23.879999</td>\n",
              "      <td>23.879999</td>\n",
              "      <td>1833100</td>\n",
              "      <td>23.879999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Open       High        Low  ...  Adj Close   Volume   close_V2\n",
              "Date                                         ...                               \n",
              "2020-07-14  22.690001  23.200001  22.690001  ...  23.160000  2228500  23.160000\n",
              "2020-07-15  23.230000  23.570000  23.230000  ...  23.549999  2162300  23.549999\n",
              "2020-07-16  23.410000  23.920000  23.410000  ...  23.879999  1833100  23.879999\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwKev2FDytT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# inline images. sometimes needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcdegvwJDyv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c6e4f0d4-18cd-42f4-d6a8-8db0d0062ea4"
      },
      "source": [
        "plt.figure(figsize=(18,4))\n",
        "\n",
        "plt.title('SPX')\n",
        "plt.xlabel('idx')\n",
        "plt.ylabel('Price')\n",
        "plt.plot(close)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# This code below caused title and labels to not work... or be printed twice....  \n",
        "from IPython.core.interactiveshell import InteractiveShell # multiline output, so `x` does `print(x)`\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import cupy\n",
        "cupy.cuda.Device(0).use() # to select device, if you have multiple GPUs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoHQzwmuDyyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90ae3eb6-273a-4c21-fe9b-2dc8396af874"
      },
      "source": [
        "np_range = np.arange(100000000)   # lives on  the CPU [0...100000000)\n",
        "cp_range = cupy.arange(100000000) # lives on  the GPU \n",
        "print(np_range) # 100,000,000\n",
        "\n",
        "#1. scale a vector\n",
        "#2. Pythagorean theorem in 100,000,000 dimensions "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[       0        1        2 ... 99999997 99999998 99999999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0L7DD5Dy1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = 9999999999999999999 * np_range\n",
        "output = 9888888888888888888 * np_range\n",
        "output = 9777777777777777777 * np_range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJzb3Lm2IVDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = 9999999999999999999 * cp_range \n",
        "output = 9888888888888888888 * cp_range \n",
        "output = 9777777777777777777 * cp_range \n",
        "\n",
        "# OMG its faster!!!\n",
        "# if I showed with a profiler, we'll see most of the time is spent transferring data to the GPU\n",
        "# output and scaler is on our CPU. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ_XMezEPYVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%timeit\n",
        "# np.linalg.norm(np_range) # 1 loop, best of 3: 227 ms per loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR5NEYBIPedu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%timeit\n",
        "# cupy.linalg.norm(cp_range) # 100 loops, best of 3: 99.7 ms per loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUHaTf9jtuD6",
        "colab_type": "text"
      },
      "source": [
        "[FFT and deTrend demo - SciPy](https://github.com/alik604/Notebooks/blob/master/DSP/Learning_DSP.ipynb)\n",
        "\n",
        "\n",
        "*   [Bettter deTrend - statsmodels.tsa.tsatools.detrend](https://www.statsmodels.org/devel/generated/statsmodels.tsa.tsatools.detrend.html)\n",
        "    * As I recall there is a better method used, and has a better plot. the source code and docs make the two look the same....\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj-JkKHBUMLm",
        "colab_type": "text"
      },
      "source": [
        "# Now for Machine Leanring\n",
        "\n",
        "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" alt=\"drawing\" width=\"900\"/>\n",
        "\n",
        "\n",
        "## Preprocessing - Convert categorical data to numerical data, so we can use ML\n",
        "*   [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) Encode target labels with value between 0 and n_classes-1.\n",
        "    + [apple, orange, banana, banana, apple] ->  [1, 2, 3, 3, 1]\n",
        "\n",
        "\n",
        "## Preprocessing - scaling numerical data\n",
        "\n",
        "We want to do this to each column. Not the the row\n",
        "\n",
        "*   [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) is my choice by default `Z = (X_i - Mean) / STD`\n",
        "> Better than MinMax for optimizing a gradient (neural networks)\n",
        "\n",
        "*   [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) `(X - X.min) / (X.max - X.min)` \n",
        "\n",
        "*   [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer) \n",
        "      * Normalize **samples** individually to unit norm.\n",
        "> Rescales the data set such that all feature values are in the range [0, 1] as shown in the right panel below. However, this scaling compress all inliers in the narrow range [0, 0.005] for the transformed number of households.\n",
        "\n",
        "*    [Docs - Guide](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#powertransformer)\n",
        "      *  PowerTransformer\n",
        "      *  QuantileTransformer \n",
        "\n",
        "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_all_scaling_002.png\" alt=\"drawing\" width=\"900\"/>\n",
        "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_all_scaling_003.png\" alt=\"drawing\" width=\"900\"/>\n",
        "\n",
        "\n",
        "## Dimensionality Reduction\n",
        "### Principal component analysis (PCA).\n",
        "\n",
        "Linear dimensionality reduction to project data to a lower dimensional space\n",
        "\n",
        "We run StandardScaler before dimensionality reduction, because: [Why do we need to normalize data before principal component analysis (PCA)?](https://stats.stackexchange.com/a/69159)\n",
        "> (Normalization is important in PCA since) it is a variance maximizing exercise. It projects your original data onto directions which maximize the variance. \n",
        "\n",
        "> My explanation: \"Gaussian is Good\". Good thing about Notebooks is that we can test to see if its a good idea or not\n",
        "\n",
        "The [Occilating movement](https://stats.stackexchange.com/a/427404) might be Gradient Descent (not so fun fact, lots of math in that link, beware) \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*XGaA7KWUlhWZLIezYEBIHA.gif\" alt=\"drawing\" width=\"900\" height = \"400\"/>\n",
        "\n",
        "[Why not PCA on all data](https://stackoverflow.com/a/40801571)\n",
        "\n",
        "Note: untested, but according to my intuition, PCA on noisy data (or pure noise) is very bad...  \n",
        "\n",
        "#### Docs - Scikit learn\n",
        "*   [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)\n",
        "*   [SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) \n",
        "*   [other](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition) \n",
        "\n",
        "### Removing data \n",
        "[my Blog post with code link, on this another cyber-sec AD dataset, on dim reduction](https://medium.com/@alik604/dimensionality-reduction-effects-on-model-accuracy-c021f4f33a61) \n",
        "\n",
        "* Remove features with low correlation to feature we want to predict `df.corrwith` \n",
        "* Remove features with (very) low standard deviations `df.std`\n",
        "* Use a Scikit-learn tree's `feature_importances_` to select which to remove\n",
        "\n",
        "...or we just stick to PCA, or other 'decomposition' methods\n",
        "\n",
        "\n",
        "## Train Test split\n",
        "leave out 15-30% of data to see if the model is useful on **unseen** data\n",
        "\n",
        "\n",
        "## Which model\n",
        "\n",
        "Treat it like a black box, dont try to understand everything. Try them all, as the code is **VERY** portable. Dispite running the the CPU, they are (often) very fast "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymnM0CNZUMIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import * \n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "import xgboost\n",
        "\n",
        "DLed = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC1Qpy37ZjPP",
        "colab_type": "text"
      },
      "source": [
        "Note that `pd.concat` and `myDataFrame.drop` both take a list, and the latter takes a axis \n",
        "\n",
        "I combine train & test to `combined_data`, so minimize work. \n",
        "\n",
        "Do not `fit` a `scaler` on the test data like I do. this is leaking information. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfoL4gGvV_Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not DLed:\n",
        "    train = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_training-set.csv')\n",
        "    test = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_testing-set.csv')\n",
        "    DLed = True\n",
        "combined_data = pd.concat([train, test]).drop(['id','label'], axis = 1)\n",
        "combined_data.shape \n",
        "combined_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wPi4_qhdXlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data.describe() # sinpkt has mean = 912; STD = 6922. I consider this to be odd and a sign of a huge skew. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxaaZvHiV_a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = train.where(train['attack_cat'] == \"Normal\").dropna()\n",
        "print('ratio of _Normal_ in Train: ', round(tmp.shape[0]/train.shape[0],5)) # 31% of train data is Normal (not an attack)\n",
        "\n",
        "tmp = test.where(test['attack_cat'] == \"Normal\").dropna()\n",
        "print('ratio of _Normal_ in Test:  ', round(tmp.shape[0]/test.shape[0],5))\n",
        "\n",
        "vector = combined_data['attack_cat']\n",
        "print(\"attack cats:\", list(set(vector))) \n",
        "\n",
        "import collections\n",
        "from tabulate import tabulate # from stack overflow, https://stackoverflow.com/questions/9535954/printing-lists-as-tabular-data\n",
        "counter = collections.Counter(vector)  \n",
        "print(tabulate(counter.most_common(), headers = ['Type','Occurences']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tnaq5axoHWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_test = collections.Counter(test['state']).keys()\n",
        "s_train = collections.Counter(train['state']).keys()\n",
        "print('NEW stuff in test set ',set(s_test)-set(s_train))\n",
        "\n",
        "counter = collections.Counter(test['state'])  \n",
        "print(tabulate(counter.most_common(), headers = ['Type','Occurences']))\n",
        "\n",
        "# s_test = collections.Counter(test['service']).keys()\n",
        "# s_train = collections.Counter(train['service']).keys()\n",
        "# print('NEW stuff in test set ',set(s_test)-set(s_train))\n",
        "\n",
        "# s_test = collections.Counter(test['proto']).keys()\n",
        "# s_train = collections.Counter(train['proto']).keys()\n",
        "# print('NEW stuff in test set ',set(s_test)-set(s_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkIlF-pLgSjm",
        "colab_type": "text"
      },
      "source": [
        "### Fixing data (\"feature engineering\") \n",
        "\n",
        "we have unseen data in the test. \n",
        "\n",
        "If we are converting categorical data to nemerical, SOMETIMES its ok to fit on test data (don't do this in NLP, \"natural language processing\")\n",
        "#### How to deal with this?\n",
        "\n",
        "if continuous, replace missings or unknown data, with the median, mean, maybe* the mode (probabily not mode...). \n",
        "* if its a time series, you can repair the data with average of nearby points\n",
        "\n",
        "if categorical, replace with the mode (never the mean or the median!) \n",
        "\n",
        "------------\n",
        "\n",
        "### SKlearn functions are simple and **consistent**\n",
        "\n",
        "[Docs - LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
        "\n",
        "Fitting to testing data is (often or arguably) leaking information\n",
        "\n",
        "*   fit(x) \n",
        ">  is akin to `map`\n",
        "*   transform(x)   \n",
        "> is akin to `apply map`\n",
        "*   fit_transform(x)\n",
        "> is akin to `map and apply map`\n",
        "*   inverse_transform(_x_)\n",
        "> is akin to `undo mapping`\n",
        "\n",
        "*   predict(X_test)\n",
        "> X_test -> prediction vector\n",
        "\n",
        "*   score(X_test, y_test)\n",
        "> portions of correct prediction\n",
        "\n",
        "* [Metrics to Evaluate your Machine Learning Algorithm](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234) - concise and to the point \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3dKEoe8eyyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data.head(1)\n",
        "\n",
        "columns = combined_data.columns # save\n",
        "categorical = ['attack_cat', 'proto', 'service', 'state']\n",
        "\n",
        "for cat in categorical: # note this type of for-loop is ok here, since we are working on a DataFrame. Python...🙄 \n",
        "  encoder = LabelEncoder()\n",
        "  combined_data[cat] = encoder.fit_transform(combined_data[cat]) # we called fit on test data..... This should be fine*, but we are technically leaking information.\n",
        "  # Test seems to have a unseen class of attack\n",
        "\n",
        "combined_data.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X8tIgKvtnDA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "_ = encoder.fit(train[cat]) # \"Returns the instance itself\", mutates `encoder` OBJ \n",
        "train[cat] = encoder.transform(train[cat])\n",
        "test[cat] = encoder.transform(test[cat])\n",
        "```\n",
        "Errror! `y contains previously unseen labels: [131, 132]`. Our train is not representative of our sample\n",
        "* [solution? dont use sklearn... HAHA](https://stackoverflow.com/a/56876351). This person fixed sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZblGR9Atrz9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = combined_data['attack_cat']\n",
        "X = combined_data.drop(['attack_cat'], axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .90, random_state=42) \n",
        "X_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek75LGRXfbDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove categorical \n",
        "categorical = ['proto', 'service', 'state']\n",
        "\n",
        "# pull out the categorical data\n",
        "print('Before: ', X_train.shape[1])\n",
        "\n",
        "train_categorical = X_train[categorical] # X_train[[ 'proto', 'service', 'state']], this is odd syntax if you think in C-style code\n",
        "test_categorical  = X_test[categorical] \n",
        "\n",
        "X_train = X_train.drop(categorical, axis=1)# Column axis \n",
        "X_test  = X_test.drop(categorical, axis=1)\n",
        "\n",
        "print('After: ', train_categorical.shape[1] + X_train.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX7rhoUpmj0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "_ = scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "pd.DataFrame(X_train).head(3)\n",
        "pd.DataFrame(X_train).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6_wcMHcfzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 39 columns. lets see the PCA from [1..39], increasing by 3 \n",
        "for i in range(1, X_train.shape[1]+1, 3):\n",
        "  print('i =', i, ', ', round(np.sum(PCA(n_components=i).fit(X_train).explained_variance_ratio_),5)) \n",
        "  # \"Percentage of variance explained by *each* of the selected components\" \n",
        "  # Note that explained_variance_ratio_ is a list, so we sum that.\n",
        "\n",
        "# to visualize\n",
        "#https://github.com/reiinakano/scikit-plot/blob/master/examples/jupyter_notebooks/plot_pca_component_variance.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCv_Eo6P4m_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-plot\n",
        "import scikitplot as skplt\n",
        "\n",
        "pca = PCA(random_state=1)\n",
        "_ = pca.fit(X_train)\n",
        "skplt.decomposition.plot_pca_component_variance(pca,target_explained_variance=0.975)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6wj3yuzUMO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=20) # want 26ish to 28ish components, if you want 99% of variance explained\n",
        "_ = pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train, index = train_categorical.index) # may or may not be needed. some recommened reseting the index  https://stackoverflow.com/a/47957914\n",
        "X_test = pd.DataFrame(X_test,  index = test_categorical.index)\n",
        "X_train.head(3)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QasCr9WExcIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # test_categorical.reset_index(inplace=True)\n",
        "# # train_categorical.reset_index(inplace=True)\n",
        "\n",
        "# X_train = X_train.join(train_categorical)\n",
        "# X_test = X_test.join(test_categorical)\n",
        "\n",
        "X_train = pd.concat([X_train, train_categorical], axis=1)\n",
        "X_test = pd.concat([X_test, test_categorical], axis=1)\n",
        "\n",
        "# X_train.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaTq8fRf0rzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.any(np.isnan(X_train))\n",
        "np.any(np.isnan(X_test))\n",
        "\n",
        "X_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyUyDNdZUMX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DTC = DecisionTreeClassifier() \n",
        "RFC = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "ETC = ExtraTreesClassifier(n_estimators=150, criterion='gini', max_features='auto', bootstrap=False)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', DTC), ('rf', RFC),('et',ETC)], voting='hard') \n",
        "for clf in [DTC, RFC,ETC, eclf]: \n",
        "    _ = clf.fit(X_train,y_train)\n",
        "    pred = clf.score(X_test,y_test)\n",
        "    print(\"Acc: %0.7f\" % (pred))\n",
        "\n",
        "    # PCA-20, 0.766 \n",
        "    # PCA-30, 0.757    \n",
        "    # PCA-36, 0.772  \n",
        "\n",
        "    # Scaler only, 0.796 (StandardScaler, not minMax)\n",
        "    # neither, 0.795"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXrKkx55-xQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Acc: %0.7f\" % (ETC.score(X_test,y_test)))\n",
        "print('feature_importances_: \\n', ETC.feature_importances_)\n",
        "print('predict_proba: \\n' ,ETC.predict_proba(X_test[:4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD51QRaZX0_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recap\n",
        "def generate_data_again(X = X, y = y, test_size = 0.9):\n",
        "\n",
        "  y = combined_data['attack_cat']\n",
        "  X = combined_data.drop(['attack_cat'], axis = 1) # inplace = true, to change-in place... mutate origianl data \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42) \n",
        "\n",
        "  train_categorical, test_categorical = X_train[categorical], X_test[categorical] \n",
        "  X_train, X_test = X_train.drop(categorical, axis=1), X_test.drop(categorical, axis=1)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  X_train, X_test = pd.DataFrame(X_train, index = train_categorical.index), pd.DataFrame(X_test, index = test_categorical.index)\n",
        "  X_train, X_test = pd.concat([X_train, train_categorical], axis=1), pd.concat([X_test, test_categorical], axis=1)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = generate_data_again() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7VIh6fC-sTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train.head(2)\n",
        "# X_train[[1,2, 40]]\n",
        "# X_train.iloc[:, [1,2,40]] # surprisingly this can take a list,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZALnpYJnX09U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "importances = ETC.feature_importances_\n",
        "print(importances)\n",
        "\n",
        "importances = np.argsort(importances, axis = 0)\n",
        "# importances = importances[::-1] # reverse \n",
        "# num_list[-10:] # a negative index will count from the end of the list, so:\n",
        "\n",
        "N = 10 # 42 -> 10 \n",
        "whitelist = importances[-N:]\n",
        "print(whitelist)\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_train = X_train.iloc[:, whitelist] # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\n",
        "\n",
        "X_test = pd.DataFrame(X_test)\n",
        "X_test = X_test.iloc[:, whitelist]\n",
        "\n",
        "X_train.head()\n",
        "\n",
        "# if we wanted to, we could take the other features, and put them in PCA, to have 40 -> 10 + 10 features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVH2bDEDX05q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DTC = DecisionTreeClassifier() \n",
        "RFC = RandomForestClassifier(n_estimators=250, random_state=1)\n",
        "ETC = ExtraTreesClassifier(n_estimators=100, criterion='gini', max_features=X_test.shape[1], bootstrap=False)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', DTC), ('rf', RFC),('et', ETC)], voting='hard') \n",
        "for clf in [DTC, RFC,ETC, eclf]: \n",
        "    _ = clf.fit(X_train,y_train)\n",
        "    pred = clf.score(X_test, y_test)\n",
        "    print(\"Acc: %0.7f\" % (pred))\n",
        "    # worse 10: 0.65%\n",
        "    # best  10: 0.7979%\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjS9sta7B3Tg",
        "colab_type": "text"
      },
      "source": [
        "This is still technically 80% accuracy, however, we needed only 10 dimensions (features) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FliUUN3tXr7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = generate_data_again() # commment this out if you want to keep using 10 dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STVhQUtVX02Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import *\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# clf = SVC(kernel = 'rbf') # 0.753, takes long\n",
        "# _ = clf.fit(X_train, y_train)\n",
        "# print(clf.score(X_test, y_test))\n",
        "\n",
        "# clf = LinearSVC() # 0.66\n",
        "# _ = clf.fit(X_train, y_train)\n",
        "# print(clf.score(X_test, y_test))\n",
        "\n",
        "clf = LinearSVC() # 0.77\n",
        "feature_map = Nystroem(n_components = 200) \n",
        "_ = clf.fit(feature_map.fit_transform(X_train), y_train)\n",
        "print(clf.score(feature_map.transform(X_test), y_test))\n",
        "\n",
        "# this tell us to use LinearSVC after a Nystroem transformer  https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RngE39mwCel0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clf = LinearSVC() # 0.76\n",
        "# feature_map = Nystroem(n_components = 100) \n",
        "\n",
        "# clf = LinearSVC() # 0.77\n",
        "# feature_map = Nystroem(n_components = 600) \n",
        "\n",
        "# clf = LinearSVC() # 0.770\n",
        "# feature_map = Nystroem(n_components = 400, gamma= 0.1) \n",
        "\n",
        "# clf = LinearSVC() # 0.769\n",
        "# feature_map = Nystroem(n_components = 400, gamma= 0.5) \n",
        "\n",
        "# clf = LinearSVC() # 0.7756\n",
        "# feature_map = Nystroem(n_components = 400, gamma= 0.99) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-BlEeUdX0zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clf = xgboost.XGBRFClassifier() # 0.765\n",
        "# _ = clf.fit(X_train, y_train)\n",
        "# print(clf.score(X_test, y_test))\n",
        "\n",
        "# clf = xgboost.XGBClassifier(n_estimators  = 100, n_jobs = -1) # 0.806\n",
        "# _ = clf.fit(X_train, y_train)\n",
        "# print(clf.score(X_test, y_test))\n",
        "\n",
        "# '''\n",
        "# With top 10 features\n",
        "# 0.7515803817063811\n",
        "# 0.7904754512604245\n",
        "\n",
        "# With top 42 features\n",
        "# 0.765262649521789\n",
        "# 0.8064819366467448\n",
        "# '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trk616Gl538s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "xgboost.plot_importance(clf)\n",
        "XGBClassifier_top_10 = np.argsort(clf.feature_importances_)[-10:]\n",
        "print('\\nTop 10: \\t\\t', np.sort(XGBClassifier_top_10))\n",
        "print('Top 10 - extra Trees: ', np.sort(whitelist))\n",
        "both = np.concatenate([whitelist,XGBClassifier_top_10])\n",
        "print(set(both))\n",
        "print(len(set(both)), \"So these two algos cared about different features. you can do stuff like this want several algos, write some code to 'vote' and select some ideal features\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4ApI5Gv3j4N",
        "colab_type": "text"
      },
      "source": [
        "So these two algos cared about different features. you can do stuff like this want several algos, write some code to 'vote' and select some ideal features\n",
        "\n",
        "these \"ideal features\" can either go to the final model (or to PCA, is not already), this is feature selection with ML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hzXWkrK6JnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcQhnhlIX0wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(2,50,3): # from 2 to 50, increasing by 3\n",
        "clf = KNeighborsClassifier(n_neighbors=20, n_jobs = -1) # 0.76\n",
        "_ = clf.fit(X_train, y_train)\n",
        "print(i, ':', clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbKIksZDX0s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5db5b22-10c0-4aae-9949-726f2d055a71"
      },
      "source": [
        "# github.com/microsoft/LightGBM\n",
        "# lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier(objective='multiclass', n_estimators= 500)\n",
        "_ = model.fit(X_train, y_train.values)\n",
        "print(model.score(X_test,y_test.values)) # 0.80\n",
        "y_hat = model.predict(X_test)\n",
        "\n",
        "print(model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8085733012513691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqVMo6fNUMbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# struct = pd.Series(model.feature_importances_, index=X_test.columns).nlargest(len(X_test.columns))\n",
        "struct = pd.Series(model.feature_importances_).nlargest(10)\n",
        "struct.plot(kind='barh', figsize=(18, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOpSeZvmUMS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture \n",
        "# # !sudo apt-get install build-essential swig\n",
        "# !curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# !pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMsHcymBxVTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import autosklearn.classification\n",
        "# from  sklearn.datasets import load_digits\n",
        "# X, y = load_digits(return_X_y=True)\n",
        "# X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
        "# automl = autosklearn.classification.AutoSklearnClassifier()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkDoiTh9xwo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# automl.fit(X_train, y_train)\n",
        "# y_hat = automl.predict(X_test)\n",
        "# print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WGklaIs8QmG",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks\n",
        "\n",
        "### Used to model complex patterns in datasets using multiple hidden layers and non-linear activation functions.\n",
        "\n",
        "Neural networks are trained iteratively using optimization techniques like gradient descent. After each cycle of training, an error metric is calculated based on the difference between prediction and target. The derivatives of this error metric are calculated and propagated back through the network using a technique called backpropagation. Each neuron’s coefficients (weights) are then adjusted relative to how much they contributed to the total error. This process is repeated till we get tried of waiting, or the \"loss function plateaus\" \n",
        "\n",
        "\n",
        "Notes: W might be called the `kernal` in the TF docs\n",
        "\n",
        "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/neuron.png\" alt=\"drawing\" width=\"900\"/>\n",
        "\n",
        "\n",
        "### Layers \n",
        "[Docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/)\n",
        "\n",
        "#### What is Dense\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Mark_Sandler2/publication/319700841/figure/fig3/AS:538663165857797@1505438714241/An-illustration-of-a-dense-layer-that-has-a-4D-input-and-3D-output.png\" alt=\"drawing\" width=\"400\" height = '300'/>\n",
        "\n",
        "#### What is Dropout\n",
        "\n",
        "> The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
        "\n",
        "\n",
        "\n",
        "### Activation Functions\n",
        "\n",
        "modify the data they receive before passing it to the next layer. Activation functions give neural networks their power — allowing them to model complex non-linear relationships. [ cheat sheet](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html) \n",
        "\n",
        "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/sigmoid.png\" alt=\"drawing\" width=\"200\"/>\n",
        "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/relu.png\" alt=\"drawing\" width=\"185\"/>\n",
        "\n",
        "(Above) Activation Functions: Sigmoid & Relu \n",
        "\n",
        "If X_1 is 100,000 and the corresponding weight, bounded between [0,1], is 0.01, the input to the Sigmoid is 10,000. The output is 1....  you get the same output for all large values of X_i, with  non \"tiny\" weigth. \n",
        "\n",
        "> recall that the sigmoid(100,000) = sigmoid(100) = 1.00; sigmoid([5..maxInt) >= 0.9933\n",
        "\n",
        "`5/100,000 = 0.00005. To weight-down a large number, we need a VERY small weight`\n",
        "\n",
        "> This is why we normalize data, among other reasons \n",
        "\n",
        "\n",
        "## Optimization\n",
        "\n",
        "Minimize Loss Function with a Optimizer, which takes `Learning Rate (LR)` as a parameter\n",
        "\n",
        "* [This is a quick reference](https://ml-cheatsheet.readthedocs.io/en/latest/optimizers.html). \n",
        "\n",
        "### I recommend using `Adam` for all cases.  \n",
        "\n",
        "> \"magically minimize the loss function\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Loss function\n",
        "Chosen to be convex functions, which means it \"has no more than one minimum\". \n",
        "> @ Minimun point, you see only: UPs and FLATs, never a DOWN \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/3096/1*6EIZU5RiHx_Um_p-Zuh4Sw.png\" alt=\"drawing\" width=\"500\" height = '400'/>\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6e/Grafico_3d_x2%2Bxy%2By2.png\" alt=\"drawing\" width=\"500\" height = '400'/>\n",
        "\n",
        "* \"Cross Entropy Loss\"/\"Negative Log Likelihood\" for Classification: `−(ylog(p)+(1−y)log(1−p)` (we minimize this) \n",
        "* \"Mean Squared Error\" for Regression `1/N * SUM[ ( X_i - Mean)^2 ]`\n",
        "\n",
        "\n",
        "* BinaryCrossentropy\n",
        "  + `2 classes` Categorization\n",
        "* CategoricalCrossentropy\n",
        "  + `> 2 classes` Categorization\n",
        "* MSE\n",
        "  + Regression \n",
        "\n",
        "\n",
        "#### Sparse vs OneHot \n",
        "* SparseCategoricalCrossentropy\n",
        "* SparseBinaryCrossentropy\n",
        "\n",
        "Sparse\n",
        "##### list = [1, 4, 4, 6, 1, 4, 6]\n",
        "##### OneHot\n",
        "<img src=\"https://miro.medium.com/max/674/1*YEJf9BQQh0ma1ECs6x_7yQ.png\" alt=\"drawing\" width=\"800\" height = '400'/>\n",
        "\n",
        "\n",
        "### Learning rate\n",
        "\n",
        "<img src=\"https://i.imgur.com/3zNiEcw.pnghttps://upload.wikimedia.org/wikipedia/commons/6/6e/Grafico_3d_x2%2Bxy%2By2.png\" alt=\"drawing\" width=\"500\" height = '400'/>\n",
        "<img src=\"https://miro.medium.com/max/918/0*uIa_Dz3czXO5iWyI.\" alt=\"drawing\" width=\"500\" height = '400'/>\n",
        "\n",
        "* Leave it at default\n",
        "* Use [ReduceLROnPlateau](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau) to Reduce learning rate when a metric has stopped improving. \n",
        "\n",
        "Docs have a code-example. import like this `from tensorflow.keras.callbacks import ReduceLROnPlateau` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt1N4AvZ8QVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Grg3zG839iV",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = generate_data_again(test_size=0.2) \n",
        "\n",
        "X_train.head(3)\n",
        "\n",
        "# ETC = ExtraTreesClassifier(n_estimators=100, criterion='gini', max_features='auto', bootstrap=False)\n",
        "# _ = ETC.fit(X_train,y_train)\n",
        "# pred = ETC.score(X_test,y_test)\n",
        "# print(\"Acc: %0.7f\" % (pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTRtwIZxZqKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder = OneHotEncoder()\n",
        "# y_train = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "# y_test = encoder.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "input_shape  = X_train.shape[1]\n",
        "output_shape = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztJRYHSW35Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "#First Hidden Layer\n",
        "classifier.add(Dense(input_shape*3, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(BatchNormalization())\n",
        "# classifier.add(Dropout(0.1))\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "# classifier.add(Dropout(0.1))\n",
        "\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer ='adam',loss='SparseCategoricalCrossentropy', metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP7lFn4-35Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train.values, y_train, batch_size=8, epochs=40, validation_data=(X_test, y_test)) # validation_split= 0.2\n",
        "\n",
        "#78%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD88QTjZaiZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(Dense(input_shape*2, activation='relu')) \n",
        "# classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "# classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.002),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test), callbacks=[reduce_LR]).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr5nDCSshEz9",
        "colab_type": "text"
      },
      "source": [
        "I didn't overfit\n",
        "```\n",
        "Epoch 100/100\n",
        "12884/12884 [==============================] - 49s 4ms/step - loss: 0.4400 - accuracy: 0.8197 - val_loss: 0.4777 - val_accuracy: 0.8155 - lr: 1.2207e-07\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeHnsatJj8uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(Dense(input_shape*2, activation='relu')) \n",
        "# classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "\n",
        "# classifier.add(BatchNormalization())\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.002),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test), callbacks=[reduce_LR]).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnIopPrrkEu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(Dense(input_shape*2, activation='relu')) \n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.002),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test), callbacks=[reduce_LR]).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq26Q83OlgZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*3, activation='relu')) \n",
        "classifier.add(Dense(input_shape*2, activation='relu')) \n",
        "\n",
        "\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.002),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test), callbacks=[reduce_LR]).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDaVLJgx35OC",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "classifier = Sequential()\n",
        "#First Hidden Layer\n",
        "classifier.add(Dense(input_shape*3, activation='relu', input_dim = input_shape)) # 129 nodes \n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dropout(0.3))\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(input_shape*3, activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dropout(0.3))\n",
        "\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(input_shape*2, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(input_shape, activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.001),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=100, validation_split=0.2, callbacks=[reduce_LR]).history\n",
        "```\n",
        "\n",
        "Epoch 100/100\n",
        "1289/1289 [==============================] - 6s 5ms/step - loss: 0.5719 - accuracy: 0.7716 - val_loss: 0.5407 - val_accuracy: 0.7852 - lr: 5.0000e-05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qss5Ridq35IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVKgGG7f35Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I37kWFoa35D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzOigzEw34_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoe3CY5s346H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def benchmark(pred, y_test = y_test):\n",
        "#   print( \"hamming_loss: \\t\\t\"    ,round(hamming_loss(y_test,pred),3))\n",
        "#   print( \"precision_score: \\t\"   ,round(precision_score(y_test,pred,average='micro'),3))\n",
        "#   print( \"recall_score: \\t\\t\"    ,round(recall_score(y_test,pred ,average='micro'),3))\n",
        "#   print(\"------------------------------\")\n",
        "#   print( \"accuracy_score: \\t\"    ,round(accuracy_score(y_test,pred),3))\n",
        "\n",
        "# benchmark(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Y2rb0n342Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cxya7UC340e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lastly, we can be very weird:  600 -> 2 -> 600 -> 2 -> 600 -> 10 \n",
        "# ANNs are good a dealing with useless vectors (a vector of the number of tweets that day from Trump)\n",
        "# ANNs can do dimensionality reduction\n",
        "# This example might be broken. if you have 10 choices, even chance, and ANN predicting 0, its 10% acc. this ACC might* only get the two most common attacks.... Im not sure \n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(600, activation='relu', input_dim = input_shape)) \n",
        "# classifier.add(Dense(600, activation='relu')) # if these two are active, if 2, we get 0.36 acc. if 600, we are fine \n",
        "# classifier.add(Dense(600, activation='relu')) \n",
        "classifier.add(Dense(2, activation='relu')) \n",
        "classifier.add(Dense(600, activation='relu')) \n",
        "\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Dense(2, activation='relu'))\n",
        "classifier.add(Dense(600, activation='relu'))\n",
        "classifier.add(Dense(10, activation='softmax'))# softmax\n",
        "\n",
        "classifier.compile(optimizer = Adam(0.002),loss='SparseCategoricalCrossentropy', metrics =['accuracy'])\n",
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "history = classifier.fit(X_train.values, y_train, batch_size=16, epochs=20, validation_data=(X_test.values, y_test), callbacks=[reduce_LR]).history # 0.62; 600 -> 2 -> 600 -> 2 -> 600 -> 10 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNTxLiKK34ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aVt3Nw58QSC",
        "colab_type": "text"
      },
      "source": [
        "# Closing remarks\n",
        "\n",
        "0. [ML cheat sheet (site)](https://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html)\n",
        "   * Concise and to the point, but project was dropped\n",
        "1. [ (Very) Approachable ML book](http://themlbook.com/wiki/doku.php) \n",
        "   * Any Software Engineer can pick this book up\n",
        "\n",
        "   * [Best ANN/MLP resource](https://www.dropbox.com/s/ouj8ddydc77tewo/ExtendedChapter6.pdf#page=7)\n",
        "\n",
        "2. [Best Machine Learning book](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)\n",
        "    * The book from my 4th/1st_grad_year ML course.\n",
        "    * I do not recommend unless you  are very comfortable with mathematical notation (equvilent to a math or stats degree) \n",
        "3. [Best Deep learning Book](http://faculty.neu.edu.cn/yury/AAI/Textbook/DeepLearningBook.pdf) \n",
        "\n",
        "\n",
        "[Best videos](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi), covers math to \"magically minimize the loss function\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlo7U7NABRJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}